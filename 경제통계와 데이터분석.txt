통계에 기반한 자료들이 학술적인 의미에서 아이디어나
 과학적인 분석이 가능하게끔하는 

정책에서도 중요, 예측, 전망, 평가를 할때 중요
계량경제학 : 경제 데이터를 분석하기 위한 정량적인 방법

타임시리즈 데이터 :

GDP와 같은 시계열 자료 =
log X : 자연로그  ->  ln X


시계열 자료 : 대상이 되는 관측치에 대해서 시점별로 관측된 데이터를 나타낸 자료
	    : 주기를 가지고 관측치가 보고됨. 연간 자료(2018 GDP, 2019 GDP)로 나올 수 있고 분기별로 나올 수 있다. 기본은 분기 발표
	    : 소비자 물가지수(CPI) - 월별(분기별로 환산가능), 거시경제의 관해서는 연간, 월간, 분기(기본)
	    : 금융지수 : 주, 일, 시간, 분, 초 등 짧기도 함 - 시점마다 연속적으로 존재
	    : Y(t), t, T	t = 1, ..., T	/ t = 2000, 2001, ..., 2020
	    : (전체 인구)임금의 평균 - 월별자료

횡단면 자료 : 시점을 고정하고 사람들에 따라서 관측된 자료들을 모아놓은 것
	    : 임금data = 특정시점 + 각각의 사람들의 임금평균(100명의 임금자료)
	    : N

패널 자료 : 시계열자료 + 횡단변 자료
	  : T x N

수준과 비율
W = 전체 소비지출
X = 식료품 지출
Y = x/w : 전체 소비지출 중 식료품 지출의 비율

성장률 = 로그 차분과 근사한 값이다.
Y(t) = t시점에서 GDP수준
r(y_t)≡Y(t)-Y(t-1)/Y(t-1) x 100 : 성장비율 % - 성장추세를 제외하고 단기적인 변동을 보기위해 성장률로 환산
r(y_t) ≒ Y(t)-Y(t-1)/Y(t-1) ≒ log(y)(t) - log(y)(t-1) : log의 변화
	: log(x)에대해 미분하면 1/x 	/ d log(x) = log(x)함수를 아주 조금 변화시킨 것 = dx/x 
	:  d log(x) = ∂logx/∂x * dx(편미분 한 것에 dx를 곱한 것) = dx/x(x의 아주 조그만 상승률)
		    (∂logx/∂x = 1/x)
	: dlog(y(t)) = log(y)(t) - log(y)(t-1) ≒ Y(t)-Y(t-1)/Y(t-1)
	
그래프 작업
  : 자료가 무엇을 보여주는지 확인 = eyeball test
  : 그래프, 히스토그램, x-y 스캐터다이어그램...
  : 일반적인 경향성을 요약하고 싶은 것. 그러나 우리는 outliers을 관찰하게 된다.

  x축에 시간(날짜), y축에 관측치 단위(UK pound) - 고정활율제
	고정환율제 - 환율 안정화
	변동환율제 - 민간의 수요와 공급에 의해 결정이 되도록
	
	97년 외환위기, 2008 금융위기 - 급격한 경제위기 : outliers가 되는 것
	그 시점을 기준으로 structure break가 일어났다고 표현

  히스토그램(예시에서 - 1992년으로 고정, 90개의 나라들 - (횡단면 자료) p.16
	x축을 소득수준, y축을 개수(빈번함)
	Bin은 구간(2000~4000 : 구간 1개)

  X-Y plots : Scatter Diagrams(산점도) - 현상의 원인을 파악하는게 경제학의 목표 -> 유용함
	두 요인간의 관계
	인구밀도와 산림손실의 관계 : x는 인구밀도, y는 산림손실 비율

좁은 의미의 통계 : 한 자료의 평균, 중앙값, 모드(최빈값), 
		 : 표준변차(중요) : 평균과의 차이의 제곱의 합을 개수로 나누고 루트를 씌운것
-----------------------------------------------------------------------------------------------------------------------------------------
상관계수 : 두가지의 경제변수가 있어서 두 변수간의 관계를 하나의 수치로 요약해서 보여주는 것
	 : 두 다른 변수간의 관계성을 알기 위해서 관계를 정량적으로 수치화 한 것
	 : 회귀 = 상관계수를 정교하게 접근하는 보여주는 것
		1. 경제 변수들간의 관계를 규명
		2. 정량적으로 수치화하기 위함 -> 예측 가능 = 전망 모형

	변수 두개가 필요함(X,Y) -> 평균을 구함 -> 한 개인의 임금, 학벌의 격차(개인 - 평균)를 다 더함
	ex) X : 학벌, Y : 임금, i = 1~100
		p = 분산/표준편차 = [개인의 (임금-평균)x(학벌-평균)을 합한 것] / [전체 임금표준편차x학별표준편차]
		  : (+) : x가 평균보다 높으면 y도 평균보다 높을 가능성이 높다
		  : (-) : 하나가 평균보다 낮으면 다른 하나가 평균보다 높을 가능성이 높다
		  : -1 ≤ p ≤ 1 : 1에 가까울 수록 관계성이 뚜렷
				 : 0이면 관계성이 떨어짐
				 : -이면 관계성이 반대로 나타난다.


ex1)	인구 & deforestation의 관계 : 상관계수p = 0.66 = 일반적인 경향성이고 모든 국가에서 필수적인 것은 아니다.
	p^2 = 0.44 : 국가간 deforestation의 변동, 44% 정도는 인구밀도의 변동과 관련이 있다.

ex2)	house price(가격, Y) & lot size(면적, X) : pyx = 0.54
						 : p^(2)yx = 0.29 -> 29% 정도가 면적의 변동과 관련이 있다.
	Z : 방의 개수, pyz = 0.37, pxz = 0.15
	
	면적이 높으면(x) 높을 수록 주택의 가격(y)을 높이는 원인이 될 수 있다. = 상관계수가 높다.
	반대는 아니다. 해석은 중요하다.

ex) 	폐암과 담배 - 경향성은 높다. 단, 다른 변수들도 존재하기에 인과관계가 명확하다고 얘기할 수는 없다.
	상관계수를 통해 인과관계로 해석할 수 있는가. 그것은 아니다.

	XY-Plots(횡단면) : p = + : 우상향, p = - : 우하향
		: perfect correlation, p = 1(우상향 직선)
		: positive correlation, p = 0.51(경향성을 갖는 모양이 보이긴 하나, 선의 모양은 아님)
		: uncorrelated variables, p = 0(관련성을 확인하기 어려움)
		: Negative correlation, p = -0.58 (경향성을 갖는 모양이 보이긴 하나, 선모양은 아님, 역방향)

		: 3개의 변수라면, pxy, pyz, pzx / 4개의 변수라면, 6개가 나옴
		  M개의 변수라면 MC2 = M x M(-1) / 2 의 개수만큼의 상관관계가 나옴
		: 이를 통해, Correlation Matrix(표) 생성이 가능 : p(x,y) = p(y,x) x,y의 순서는 상관X, 두 변수의 경향성이기 때문
								 : p(x,x) = 1 똑같은 변수의 경향성은 같으므로 1

	 Cross corrlations(시계열) : 
		: 같은 연도의 실업률, 인플레이션율의 상관관계 : p(xt,yt) = var(xt,yt)/루트var(xt)x루트var(yt)
	           (시차 상관계수) : 다른 시점에서의 상관관계 : p(xt+k,yt) = var(xt+k,yt)/루트var(xt+l)x루트var(yt)
		                   : t연도의 실업률이 다음 년도의 인플레이션과 같는 관계
				   : 상관계수가 +이면 경기에 순행, -이면 경기에 역행 - GDP(기준)
				   : 경기 선행. 후행하는지 파악하는데 도움이 됨 - GDP(기준)
		
		ex) 동시점 : 
		    소비와 GDP의 상관계수 : 0.85
		    정부소비와 GDP와 상관계수 : -0.09 -> 정부소비는 경기 상황과 상관X, 정부의 지출이 경기 역행적 = 바람직함
		    건설투자 : 0.61
		    설비투자 : 0.83 
		    수출 : 0.32, 수입 : 0.86 -> 경기가 좋을 때는 (특히 설비투자)투자가 활성화됨
						ex) 반도체 : 생산량을 늘리기 위해 장비들을 수입하게 됨

		    무역수지 : 수출 - 수입 : 경기 역행적(GDP대비 상대적인 규모 줄어듬) : -0.64
							흑자폭의 규모가 줄어든다기 보다는 덜 늘어난 것일 수도 있음
			     : 경기가 안좋고 수출이 잘 안되더라고 투자가 더 민감하게 감소하고 수입도 감소하기 때문에 무역수지가 늘어나는 것이 특징
		    경상수지 : -0.62

		    건설투자가 선행성이 강하다. 동행성 보다는 : 0.65
		    수출, 경상수지, 무역수지 : 동시점보다 후행성이 더 강하다 : 0.34, -0.64, -0.65

		    : 경기↑ = GDP↑ = 실업률↓, 경기↓ = GDP↓ = 실업률↑ : 실업률이 역행적이다.
		      2000년대 들어서 실업률과 경기상황의 역행 관계가 약화되었다. why) 실업률 자체의 통계(설문base)이기 때문
-----------------------------------------------------------------------------------------------------------------------------------------
------------------해석하기---------------------------
표준편차를 구해보면, 80년대 중반을 기점으로 변동폭이 줄어듦 = 대 안정화기

80년대 초반이 지나면 변동폭 자체가 줄어듦 = 대안정화기

필립스 곡선 : 실업률과 인플레이션의 관계
	    : 대개, 실업률이 ↑ = 불경기, ↓ = 호황
	    : 70-80년대 : 오일쇼크, 2000년 초반 : 금융위기 - 실업률 상승
	    : 대개, 인플레이션은 경기가 좋을 때 높아지고, 경기가 나쁠 때 낮아진다.
	    : 실업률 - GDP : 역의 관계 = 오쿤의 법칙

	 대개, 경기가 좋을 때, 인플레이션이 높다 → 실업률 ↓
	       경기가 나쁠 때, 인플레이션이 낮다, 디플레이션 → 실업률 ↑ 따라서, 역의 관계가 나타난다.

	인플레이션 압력이 높아지면 금리를 높이고, 압력이 낮아지면 금리를 낮추는 경제안정화 정책을 시행
	→ 인플레이션을 낮추기 위해서 금리를 올렸을 때, 실업률이 높아지는 방향으로 갈 수 있다.

70년대 이후에 이러한 관계가 깨지기 시작함
  : 스테그플레이션 = 인플레이션↑, 실업률↑

fitlm : 선형회귀
-----------------------------------------------------------------------------------------------------------------------------------------
Regression(회귀분석)

정의 : 두 개 혹은 더 많은 변수들간의 관계를 분석
  ex) 실업률 - 인플레이션 : 필립스 곡선
      실업률 - 경기변동 : 오쿤의 법칙

  ex) 주택의 가격 - 방 개수, 평수..

단순 회귀분석(simple regression) : 두개의 변수 - Scatter diagram
  : 산포도 → 점들간의 거리를 최소화할 수 있는 선
  : 예상하는 과정에서 필요로 하는 것 = 함수관계를 찾는 일

  : 까만 점이 data point, 선 : 선영함수 식(Y = α + βX)
  : Y = α + βX	/ Y = 주택가격, X = 방의 개수, α = 특정 값을 지니고 있는 고정값(Y절편), β기울기

  : 측정 오차 = 실제 관측 자료와 임의로 설정한 함수관계(회귀선) 사이의 차이

  example) House price Y, Lot size(square feet) X
	   Y = 34,000 + 7X	/ α = 34,000, β = 7

	   그렇다면, 5,000 square feet는 $69,000여야 한다. 하지만 모든 데이터가 그런 것은 아니다.
	   따라서, 근사화된 관계를 선영 회귀식으로 표현한 것이다.(approximation of the true relationship)
	   정확한 것은 아니므로 오차가 발생하고 이는 관측되지 않은 요인에 의해서일 수 있다. missing variavles, 관측치가 없다.

	   Y = α + βX + ε	/ Y : 종속변수, X : 설명변수(독립변수), α,β : 계수, ε: error, 오차(항)
	   			/ X → Y(cause) : 인과관계, 매번 인과관계로 해석하는 것은 아님
				/ β계수값으로 관련성을 나타내는데 인과관계의 결과인지 통계적인 관련성에 의한 것인지 구분이 필요
  
  이자율 - 주식가격 : 이자율↑ 단기적 : 자본의 흐름을 흡수, 
			       장기적 : 경제가 좋아지고 있는 신호, 인플레이션 압력이 높아지고 있다.
		    		      : 주식 - 비즈니스의 기반을 반영
		     : 단순히 이자율이 주식 가격에만 영향을 주는 것이 아니라 주식가격이 오르는 것 자체가 이자율을 높히는 반응

  일반적인 인과관계로 해석X

  회귀선을 어떻게 그을 것인가(Estimation 추정)
    : 주택가격은 주택의 면적에 선형함수 관계를 갖고있다.
    : 자료를 활용해서 선을 긋는 것 = 추정하다.
    : 계수값에 대한 추정치를 α(^), β(^) : 특정값이 주어졌다.
    : 가장 적합한 선을 긋는 것 = 선형회귀식에 대한 추정

    error : ε(t) = Y(t) - α - βX(t)			: 오차항 = 모르는 변수
    residuals : u(t) = Y(t) - α(^) - β(^)X(t) 	: 잔차항 = 실제로 숫자가 있는 변수 → u(t)를 계산
	
    실제 B라는 주택의 가격 - 선형회귀선에 의한 B 주택의 면적에 따른 가격 = u(2)
      추정가격 : B라는 주택의 면적 x β(^) + α(^) = B 주택의 추정 가격(Y(^))
      실제가격 : Y(2)
    u(2) = Y(2) - Y(^)		/ u(1, 2, 3...) = 잔차항

    Best fitting line → 잔차항들의 거리(SSR)가 최소화 되도록 만든 선(최소자승추정법 = OLS)
      : 잔차항(u)들을 계산하고 나면 제곱해서 다 더함(= SSR)

      : SSR = u(1)^2 + u(2)^2 + u(3)^2 +...+ u(N)^2 = 잔차항의 "총거리"
    	    = ∑u(t)^2	(t=1 ~ T)
      : Y를 X에 대해서 회귀추정을 한다.

  y ≡ {Y(1), Y(2), Y(3)... Y(T)} : Y에 대한 관측치(숫자벡터) : T x 1(차원)
  x ≡ {X(1), X(2), X(3)... X(T)} : X에 대한 관측치(숫자벡터) : T x 1(차원)
  ε≡ {ε(1), ε(2)...ε(T)} : 모르는 수, 오차항 : T x 1(차원)

	y = α + βX + ε			/ 벡터 형태 : 데이터가 한꺼번에 들어가 있음
	Y(t) = α + βX(t) + ε(t)		/ ∀t=1, ... , T

   Best fitting line → 잔차항들의 거리(SSR)가 최소화 되도록 만든 선(최소자승추정법 = OLS, β를 찾는 것)
			β(^)OLS = arg(β) min SSR(β) = ∑ε(t)^2 = ε'ε = (y-βX)'(y-βX)
				  T
			SSR(β) = ∑u(t)^2 = ∑ε(t)^2 = ε'ε = (y-βX)'(y-βX)	/ β가 있으면 SSR이 정해짐
				  t=1

			이때, y = α+βX+ε → ε=y-βX-α(α는 일반성과 상관X 제외가능)
			(') : 열벡터를 행벡터로 전환, [ε(1)...ε(T)] |ε(1)|	
								      | ... |
							  	      |ε(T)|

			OLS : 선을 긋는 작업(잔차항들의 거리를 최소화), 선은 β의해 결정
			거리의 총합(SSR)을 β함수로 정의, 함수를 최소화 시키는 β를 찾는 것
	
			y = f(x) 	x(^) = arg(x) min y = f(x)	f'(x(^)) = 0
-----------------------------------------------------------------------------------------------------------------------------------------
SSR이라는 목적함수가 존재, 주어진 자료하에서 β를 찾는 것인데, SSR은 β에 대한 함수이고
목적함수SSR을 최소화 시키는 β를 찾는 것 = OLS
β^2이 존재하므로 2차함수이고 제곱이므로 양수값을 항상 갖고 극소점을 갖는다 = 최소점이 존재 = 미분을 통해 구하기

목적함수 = SSR, x값 β, 기울기가 0이 되도록하는 β를 찾는 것

SSR(β) = (y - Xβ)'(y - Xβ) = (y' - β'X')(y - Xβ)				/ (AB)' = B'A'
			      = y'y - β'X'y - y'Xβ + β'X'Xβ			/ (β'X'y)' = y'Xβ
			      = y'y - 2y'Xβ + X'Xβ^2	-> 2차 방정식이 됨

FOC : ∂SSR/∂β = 0	->    ∂SSR/∂β = - 2y'X + 2X'Xβ(^) = 0		/ 거리의 합이 최소화가 되도록하는 기울기이기 때문에
일계조건				   (1xT Tx1  1xT Tx1	1x1)		/ β(^) : 베타 헷이 됨
					 = X'Xβ(^) = X'y
					 = β(^)OLS = (X'X)^(-1)X'y		/ OLS 추정법에 의해 찾아낸 β(^)은 위와같은 계산으로 이루어진다.

α : 절편, 상수항에 대한 경제학적 해석은 거의 의미가 없다.
β : 의미는 중요(기울기 = β가 변함에 따라 Y값도 변화한다.)
   : β(^)이 양의 값을 갖는다면 경제변수X와 Y의 관계가 양의 상관관계를 갖는다.
   : 정확히는, 통계적으로 봤을 때 X가 1만큼 늘어났을 때, Y는 β만큼 변화한다. → dY/dX = β
   = 한계효과(marginal effect), 일반적인 경향성을 보여준다.

적합도(R^2)를 통한 평가	
  1. 가설 : 경제 변수들간의 관계를 식, 함수로 가정 → [선형회귀] y = α+βX 
  2. 추정 : 방법론 선택 			   → [X,Y](t=1~T), OLS, α(^), β(^)
  3. 평가 : R^2는 상관계수의 제곱		   → y = α(^) + β(^)X

각각의 시점 t에 대해서 Y(t) = α + βX(t) + ε(t) 이런 선형회귀 식이 있고, OLS에 의해서 α(^), β(^)을 찾았고
		       Y(^) = α(^) + β(^)X
Y(^)은 이렇게 추정된 회귀식에 의해서 계산된 적합치를 의미 = 선상에 놓여있는 Y값 (Y 헷이 없으면 관측된 자료 그대로)

얼마나 이 적합치가 좋냐는 것은 실제관측된 Y와 적합치Y(^)의 차이가 크냐, 작냐로 판단
	u(t) = Y(t) - Y(^)(t)
			      T				/ TSS는 관측된 자료 자체에 대한 분산 = Y(t)자체의 분산
퍼진 정도 측정하기 	TSS = ∑(Y(t) - Y(-)(t))²	/ 평균에서 뺀 차이를 제곱해서 더함
			      t=1
		 	TTS / T-1 (= 분산)		/ TTS를 전체(자유도)로 나눔
							/ 변수가 T만큼 있지만 평균치에 의해 묶여진 게 있어서 T-1이라고 함

			TSS = RSS + SSR			/ OLS추정에 의해 목적함수로 삼았던 총거리 SSR
							
		        RSS = ∑(Y(^)(t) - Y(-))²	/ 모형에 의해 추정된 적합치들의 분산 = Y(^)(t)자체의 분산

  1. TSS = ∑(Y(t) - Y(-))²		/ Y(t)의 분산정도 
  2. RSS = ∑(Y(^)(t) - Y(-))²		/ Y(^)(t) = 적합치의 분산정도
  3. SSR = ∑(Y(t) - Y(^)(t))²		/ 잔차항의 제곱의 합
  4. TSS = RSS + SSR	

      0  = ∑[2Y(^)(t)(Y(^)(t)-Y(t)) - 2Y(-)(Y(^)(t)-Y(t))]
                           u(t)			 u(t)
      0  = 2βx'(xβ - y) - 2Y(-)Y(-)u(t)
		=0		=0 
  4. TSS = RSS + SSR 전체를 TSS로 나누면
      1 - SSR/TSS = RSS/TSS ≡ R²			/ Yt 자체의 분산에서 모형에 의한 적합치 분산의 비율
							/ Yt의 변동성 대비, 선형회귀 적합치의 변동성 비율
     R²는 Y자료 자체의 변동성 중에서 x에 의해 설명되어 지는 비중이 얼마나 되는가
     TSS ≥ RSS, TSS ≥ SSR, 0 ≤ R ≤ 1

그렇다면 항상 선형회귀 식으로 가정을 하느냐, 그건 아니다. 2차함수의 형태(quadratic)도 가능하다.
	Yt = 6X²(t) 
	설명변수 자체를 관측치들을 제곱해서 넣으면 된다. X²으로 대신한다.	Zt = X²(t) → Yt = αZt
	관계 자체를 어떻게 선형의 관계를 표시하느냐가 관건
	
	가장 흔한 형태는 자연로그	log X	
		why) 1. 해석이 쉽다. 계수값(β)이 탄력도라는 것과 정확히 일치
		     2. 로그 차분 지금시점의 로그수준에서 이전시점의 로그수준을 뺀 것이 성장률, 증가율과 근사값을 가짐
				log Xt - log Xt-1 ≒ Xt-Xt-1/Xt-1
		     3. 많은 경우, 경제변수 자체로 선형회귀식을 만들 때, 관계가 선형관계로 나타난다.

		∂log x / ∂x = 1/x
	 	탄력도 : x가 1% 증가했을 때, y는 몇 % 변하는가? 단위와 상관없이 상대적인 변화율을 %로 얘기가능
		εx,y = y의 변화율 / x의 변화율 = dy/y / dx/x

		∂log x / ∂x = 1/x	==	d logx / dx = 1/x	/ 편미분과 전미분의 경우가 같다
		d log x = dx/x		-> 우변은 x의 변화율, 좌변은 로그의 변화분

		탄력도 = d log y / d log x	-> log x 가 1만큼 변했을 때 log y는 얼만큼 변하는가
						   x가 1% 변했을 때 y는 몇 % 변하는가

		β = dY/dX = x가 한단위 변하면 y는 얼만큼 변하는가
			   = d log y / d log x = log x 가 1만큼 변했을 때 log y는 얼만큼 변하는가 = 탄력도의 개념
					       = x가 1% 변했을 때 y는 몇 % 변하는가

	log(Y) = α + βlogX + ε(t) 	/ 이때, β는 d log y / d log x의 개념이 되고 탄력도(εx,y)를 통해 %로 측정가능
-----------------------------------------------------------------------------------------------------------------------------------------
선형회귀 방정식 : 변수가 2개라면 산점도를 그렸을 때 회귀선을 그리는데
		: 산점도의 점들과의 거리가 최소가 되는 선형식을 찾아내는 것.
		: 기울기와 절편에 대한 추정치로 나옴

statistical aspects of regression = statistical inference

  회귀모형이 어떤 통계적 방법론이 적용이 되는지
  결과의 해석 
  그래프를 통해서 이해

  Y(t) = α + βX(t) + ε(t)	/ t = 1, .., T
				/ true model : 이 모형의 진리가 어딘가 있다.
				/ 우리는 Yt, Xt만 알고있고 이를 이용해 추정하는 것이다.

  고전적인 통계분석의 추론방법

   Y(t) = α^ + β^X(t) + ε(t)		/ ^이 없으면 모르는 수, 있으면 데이터에 의해 추정된 수치 = 숫자
   α^,β^ : 거리를 최소화하는 OLS 추정치 단, α,β와 정확히 일치하지 않는다. = true값이 어딘가 있을 것
									      = 데이터에 의한 추정치
  OLS 추정치가 얼마나 정확한가
	1. 신뢰구간
	2. 가설검정

  앞에서 deforestation과 population density의 예에서
	1. 회귀방정식 추정결과 : β^ = 0.000842
	2. 추정 신뢰구간 : 0.0006 < β < 0.0010
	3. 따라서 true β는 0.0006 < β < 0.0010 범주 사이에 있을 것이라 자신한다.

  유의수준이 얼마냐에 따라 신뢰구간의 폭이 달라짐
  대게 95%의 신뢰구간에서 β는 그 구간에 존재할 것이다. = confidence level
  
  신뢰구간 Hypothesis Test	
	: Xt라는 설명변수가 Yt를 설명하는데 있어서 설명력이 있는가 없는가를 판단하고 싶다면 β는 유의미한 수준이어야 함
	  그래서 우리는 귀무가설, β = 0 , 설명변수의 설명력이 전혀 없다고 가설
	  = 이 귀무가설이 True이면 설명변수는 설명력이 없다.
   	: 가설 : true β = 0

	: 만약, true model이  Y(t) = α^ + β^X(t) + ε(t) 이것이고 
	  true 값이 α=0, β=1이라 시뮬레이션하면
	  (true model을 선정해서 데이터를 만들어냄, 그 데이터로 모형을 추정해서 다시 α^,β^을 구해봄)
	  α^,β^ 실제 true α,β와 비교함으로써 신뢰성을 판단할 수 있음 
	  4가지 다른 데이터 셋을 만들어 볼 수 있다.	/ {yt,xt}^T_t x 4
	  각 세트별로 α^,β^을 추정함으로써 true값에 얼마나 근접하느냐로 신뢰성 확인이 가능하다.

  표본자료가 5개 인데, 아까 true model을 가지고 data point를 generate한 것 {xt,yt}^5_1	/ 1부터 5까지
  ... {ppt sample size 참고}

  지금까지의 βˆ₁, βˆ₂, βˆ₃, βˆ₄가 true β에 가까울 것인가. 또, 얼마나 설명을 잘 하고있나. β^₃
	1. eyeball test
  	2. 추정치의 정확도를 결정하는 3가지 요인
		1. 데이터(표본자료)가 많아야 한다. more data point
		2. 오차항의 분산이 작아야 한다. SSL is small
		3. x의 관측범위가 넓으면 넓을 수록 다양한 수준에서의 x와 y의 관계를 보여줄 수 있다.

  신뢰구간의 계산
	1. 위의 3가지 결정 요인으로 신뢰구간의 크기가 바뀜
	2. 신뢰구간이 좁다 : 정확하다.
	   신뢰구간이 넓다 : true β를 예측하는 불확실성이 높다.
	   [βˆ − tbsb, βˆ + tbsb] = βˆ − tbsb ≤ β ≤ βˆ + tbsb 
		
		: true β는 OLS 추정치에서 tbsb를 빼고 더한 사이에 존재
		  βˆ : true β에 대한 OLS 추정치
	sb :	  sb : βˆ의 표준오차, standard error, 표준오차 → 작으면 true β의 범위가 좁아짐
								→ 크면 예측이 불확실하다. 신뢰구간이 넓어짐
		  SSR = ∑(Yt-α^-β^Xt)
		  sb = sqrt SSR / (T-2)∑(Xt-X(-))²	/ T-2인 이유는 α,β가 존재하기 때문
							/ (Xt-X(-))²= x의 분산

		  분자 : SSR = 거리			/ 거리↑ 오차↑
		  분모 : T = 표본자료의 개수		/ 데이터 ↑ 오차↓
		       : ∑(Xt-X(-))²= x의 분산	/ x의 분산이 ↑ 관측이 크면클수록 정확도↑ 가능성

	tb :	  신뢰구간(확신)의 범위를 결정
		  1. 신뢰수준에 의해 결정 90%, 95% 99%
		  2. T = 표본자료의 개수로 결정(T-K라는 자유도에 의해 결정)

		 	ex) 자유도 28, 신뢰수준 95% → tb = 2.048
			만약 99%라면 신뢰구간이 넓어질 수 밖에 없음 why) 95%의 확률로 값이 있을 것이다의 구간보다
									 99%의 확률로 값이 있을 것이다의 차이임
			자유도가 높을수록 정확도가 올라가기 때문에 신뢰구간이 조금씩 줄어듦(확신)
-----------------------------------------------------------------------------------------------------------------------------------------
OLS 추정치에 대한 True 모델이 있다면 True값이 어디에 위치해 있을지 신뢰구간을 통해 계산
1. 데이터(표본자료)가 많아야 한다. more data point
2. 오차항의 분산이 작아야 한다. SSL is small
3. x의 관측범위가 넓으면 넓을 수록 다양한 수준에서의 x와 y의 관계를 보여줄 수 있다.

가설검정 : 계수값에 대한 가정을 세우고 그 가설을 기각하거나 기각할 수 없을 때 설명변수의 설명력이 좋은지 나쁜지를 확인
Null Hypothesis : 귀무가설 : 고전적 통계접근 방법
  H(0) : 귀무가설
  H₁: 대립가설

  통상적 귀무가설 : β=0		/ 귀무가설 = 설명변수가 종속변수에 대해서 설명력이 없다를 검정
					/ β=0라는 귀무가설을 기각하는 것! = 설명변수의 설명력이 없다를 기각

  만약, 종속변수가 소득이고 설명변수가 학벌이라 하면 
	1. 학벌↑소득↑라는 경향성을 scatter diagram. 
	2. 상관관계를 파악하면 상관성이 파악
	3. 회귀분석 → 상관성이 유의미한지	/ 그 외에도, 마케팅 정도와 매출, 정부의 직업훈련 프로그램과 실업률

  신뢰구간을 구하는 것 = 가설 검증하는 것 같은 얘기임

  True값이 β=0이라면 β의 추정치를 통해 신뢰구간을 그려볼 수 있고 
	1. 신뢰구간 안에 0이 없으면(β=0이라는 사실을 신뢰할 수 없으므로) 귀무가설이 틀린 것
	2. 신뢰구간 안에 0이 있으면 귀무가설이 맞는 것. β가 0이라는 사실을 기각할 수 없다. 설명변수의 설명력이 떨어진다.

	β=0이라는 가설을 기각하는 경우 X라는 설명변수가 Y 종속변수에 대해 유의미한 설명력을 가진다.
	90, 95, 99(%)에서도 기각이 된다면 설명력이 굉장히 높다.
	90에서 기각, 95%에서 기각을 못했다면 신뢰수준 90%에서 기각을 한 것이고 유의수준 10%에서 통계적으로 의미가 있는 것

	신뢰수준 90%, 95%, 99%
	유의수준 = 1 - 신뢰수준 10%, 5%, 1%	유의수준 5%에서 β=0을 기각한다 = 신뢰수준 90%에서 설명변수는 설명력이 있다.

  검정 통계량(test statistic) : β=0인 것에 대해서 t-통계량
	t = βˆ/sb		/ βˆ을 β의 표준편차로 나누면 평균적으로 표준편차가 1인 범위에서 왔다갔다 하는 표준화된 수치가 됨
	
	standardize : 표준화 : 원래 변수에 자기 변수의 표준편차로 나누면 분산이나 표준편차가 1이 됨

	(절댓값 기준)t-통계량이 크면 클수록 βˆ이 0으로 부터 먼 것 = 귀무가설을 기각 (β≠0)
	(절댓값 기준)작으면 작을수록 βˆ이 0에 가까움
	p(t > tk) < 5% : 높은 확률로 0으로 부터 멀다
	경계선 : critical value, 유의수준이 낮으면 낮을수록 점점 거리가 멀어짐
	
	우리가 계산한 t-통계량이 1%보다 우측에 있다면 1% 유의수준에서도 귀무가설을 기각한다. = 높은 설명력
	만약 1~5% 사이에 있다면 1% 유의수준에서는 기각할 수 없지만 5% 유의수준에서는 기각할 수 있다. = 꽤 멀다
	만약 5~10%사이에 있다면 5% 유의수준에서는 기각할 수 없지만 10% 유의수준에서는 기각할 수 있다. = 설명력이 약간 있다.
	10%보다 안이라면 0으로 부터 멀지가 않다고 함

	분포 자체는 자유도에 따라서 알게되고, critical value는 유의수준을 정해서 찾을 수 있다.

	t-통계량을 계산했을 때, 면적을 확률이라고 했고 이를 p-value라고 함
	확률 밀도함수를 적분해서 면적을 구하면 1이 나옴, 개별 t값에 대한 확률을 보여주는 것이므로 확률의 총 합은 1임
	: p-value는 아무리 커봐야 1이라는 것이고 t-통계량이 만약 1%보다 작다면
	  유의수준 1%의 critical value보다 작다 = 유의수준 1%에서 귀무가설을 기각O

	10% 유의수준에서 t-통계량이 더 크려면 p-value는 10%보다 작아야 한다.
 	1. p-value가 크면 클수록 0으로 가까워짐(확률이니까 면적을 많이 먹음) = 귀무가설 0을 수용(0일 확률이 높다는 거니까)
	2. p-value가 작으면 작을수록 0에서 멀어짐 = 귀무가설 β=0을 기각함
	
	1.βˆ이 표준오차sb에 비추어 봤을때, 크다고 하면 βˆ이 큰 값인만큼 t-통계량도 큰값이 나오고 0에서 멀다
	2. critical value에 따라 멀다 멀지 않다를 판단
	3. p-value는 0~1사이의 값이고 1,5,10보다 작냐만 판단하면 됨, 
	   β=0일 확률을 구해줌, t-통계량이 0에서 멀면 멀수록 p-value가 작아짐. 즉, β = 0일 확률이 작아진다.
 	   p-value가 5%보다 작으면 t-통계량이 크다. β ≠ 0
	   p-value가 5%보다 크면 t-통계량이 작다. β = 0
 
  가설검정의 일반적 구조
	1. 검정할 가설 구체화
	2. t-통계량 계산 βˆ/sb
	3. critical value(tb)와 t-통계량을 비교		/ 통계패키지 : βˆ, t-통계량, p-value

  	R²: 전체적인 설명력을 보여주는 수치(모형 전체)
	t-통계량, p-value: 특정 설명변수의 설명력을 보여줌

  	1. TSS = ∑(Y(t) - Y(-))²		/ Y(t)의 분산정도, Y의 전체적인 변동성
	   TSS = RSS + SSR			/ RSS : 회귀식의 모형에 의해 설명되는 변동부분
						/ SSR : 회귀선에 의해 설명되지 않는 변동부분

 	2. RSS = ∑(Y(^)(t) - Y(-)t)²		/ Y(^)(t) = 적합치의 분산정도, 잔차항과 평균의 거리
  	3. SSR = ∑(Y(t) - Y(^)(t))²		/ 잔차항의 거리의 합, 오차들의 분산


	R²= 1-SSR/TSS = RSS/TSS : 모형에 의해 설명되는 Y의 변동/전체적인 Y변동
	따라서, R²= 1이라는 말은 모형과 전체적인 변동이 일치한다는 것, SSR = 0이라는 것
		모형 자체의 설명력을 보여줌

	모든 설명변수들이 여러개일 수 있다.
	t-통계량 : 특정 설명변수(β=0)의 설명력을 보여줌

	전체적인 설명력이 좋다, 나쁘다, R²≒ 1이 설명력이 좋은 것이므로
	귀무가설 : R²= 0이라고 두고 검정이 가능하다.
	F-통계량 : R²= 0이라는 귀무가설에 대해서 가설을 검정하는 것
	F = (T-2)R²/ (1 - R²)		/ 설명변수가 2개임 (T-k)

	F-통계량이 critical value에 비해 밑에 있으냐 밖에 있느냐
	  : 밑에 있으면 0에서 멀지 않으므로 모형의 설명력이 좋지 않다
	  : 경계선보다 밖이라면 설명력이 꽤 높은 것
-----------------------------------------------------------------------------------------------------------------------------------------
실습
  OLS : 설명변수 내용이 1번째 열, 원본 내용이 2번째 열

  X1          = [ones(size(FIG51,1),1) FIG51(:,1)];		/ 설명변수 x
  inv(X1'*X1)*X1'*FIG51(:,2); 					/ 1행 α, 2행 β
  Y1_hat      = X1*BETA1_hat;					/ 설명변수 x β^
 
위와같이 일일이 설정하여 Y를 구할 수 있으나 한방에 하는 방법

  FIG51 = readmatrix('FIG51','Range','A2:B6');		/ 엑셀읽기

  FIG51_hat   = fitlm(FIG51(:,1),FIG51(:,2));         	/ fitlm() : OLS추정명령, 첫번째 argument가 설명변수, 두번째 argument가 종속변수


  BETA1_CI    = coefCI(FIG51_hat);        		/ coefCI : 추정된 모형의 신뢰구간을 계산
  BETA11_CI   = coefCI(FIG51_hat,[0.01 0.05 0.1]);    	/  99%, 95%, 90% 신뢰구간

  1번째 행 = 상수항, 2번째 행 = 설명변수
  1번 열 = 왼쪽, 2번째 열 = 오른쪽 : 범위
  한번에 하면 좌측 모아서 작성됨, 모아서 우측에 작성됨(1열, 4열 = 99%, 3열, 6열 = 90%)

결정계수(R²): 0.313

추정된 계수:
                    Estimate        SE         tStat        pValue   
                   __________    _________    ________    ___________

    (Intercept)    -0.0080132      0.02781    -0.28814        0.77385
    x1                 1.0026    0.0085589      117.14    3.9168e-107		pValue가 설명변수X에 대해  3.9168e-107 낮은 값을 가짐
										0일 확률 = 3.9168e-107

상수 모델에 대한 F-통계량: 1.37e+04, p-값 = 3.92e-107
   -0.0632    0.0472
    0.9856    1.0196			/ 신뢰구간이 명확하다. 해당 범위 안에 추정값이 있을 것이므로..
					모형 전체의 설명변수의 설명력
변동성 = 표준변차

set_OLS1    = table(HPRICE(:,2),HPRICE(:,3),HPRICE(:,1),'VariableNames',{'LotSize','Bedrooms','HousePrice'});
		     설명변수     설명변수   종속변수  			   설명변수  설명변수  종속변수

OLS1        = fitlm(set_OLS1,'HousePrice~LotSize');
				종속변수~설명변수
-----------------------------------------------------------------------------------------------------------------------------------------
기말고사 = Multiple regression model ★★★★★★★★
-----------------------------------------------------------------------------------------------------------------------------------------
설명변수가 종속변수에 대해 얼만큼의 설명력을 갖고있는가. 통계적 유의성이 어느정도 인가
  : T-통계량, 표준오차, 신뢰구간, p-value 
  : p-value로 판단하는게 가장 쉽다. why) p = 확률이기 때문
  : p-value ↓ = 귀무가설 기각 : β≠0, 0에서 멀다. = 설명력이 높다. 계수값의 추정치는 통계적 유의성이 있다.

다중회귀
  ex) 주택가격 : 주택가격에 영향을 주는 요인들이 많음
      X₁= 면적, X₂= 침실개수, X₃= 욕실개수, X₄= 층수  → 종속변수에 얼만큼의 영향?

  단일 회귀 : 계수값이 과대추정 될 수 있다. 설명변수가 종속변수에 미치는 영향이 과대추정될 수  있다.
	
  Y = α + β₁X₁+ β₂X₂+ ... + β_kX_k + ε
  우리가 알고싶어 하는 것은 추정치 : α^, β^₁, ...β^_k

  SSR = ∑(Y - α^ - β^₁X₁- β^₂X₂- ... - β(k)^X_k)²= ∑ε(t)²
  
  R²= 모형에 의해 설명되는 Y의 변동(y^)/전체적인 Y변동(y)
  이것에 상응하는 F-통계량 : 설명변수의 개수가 늘어나면 (N-1)에서 (N-k-1)로 자유도 설정
  T-검정 : 특정 설명변수(β=0)의 설명력
  F-검정 : 모형 전체의 설명변수의 설명력

  Matrix notation : Subscript X_t : t를 말함.	X₁_t = X sub 1 t

   x(t) = |x(1t)|	β   = |β₁|
  K x 1   |x(2t)|      k x 1   |β₂|
	  | ... |	       | ...|
	  |x(Kt)|	       |β_t|

    y   = |y(1)|	ε   = |ε(1)|		y : 종속변수
	  | ...|	       | ... |
   Tx1	  |y(T)|	Tx1    |ε(T)|		X : 설명변수, 관측치 표본 → Matrix

    X	= |x₁'| = |x(11) ... x(K1)|		x₁'= x(11) x(21) ... x(K1)
	  | ...| = | ...	...|
   TxT	  |x_T'|   |x(1T) ... X(KT)|		/ 행 : 시점, 열 : 설명변수


위의 식을 정리하면 : y(t) = x'tβ + ε(t)	/ 특정시점 t에 대한 회귀방정식
		
		    : y  =  X  β + ε
		     Tx1   Txk kx1  Tx1

  OLS를 통해서 β^을 계산해야 하기 때문, β^OLS
	ε(t) = y(t) - x'tβ
  		    T
	SSR(β) ≡ ∑(y(t) - x'tβ)²= (y - xβ)'(y - xβ)	/ β를 찾기 위해서는 β를 변수로, 나머지는 숫자로 생각
		   t=1
	SSR = β에 대해서 미분해서, 미분함수가 0이 되는 β를 찾는 것 = β^
	β^ = arg min SSR(β)					/ SSR을 최소화하는 β값을 찾는 것

	SSR(β) = (y - Xβ)'(y - Xβ)
		= (y' - β'X)(y - Xβ)
		= y'y - β'Xy - y'Xβ + β'X'Xβ
		= y'y - 2y'Xβ + β'X'Xβ			: s(yy) = y'y, s(xy) = x'y, s(xx) = x'x
		≡ s(yy) + 2s'(xy)β + β'S(xx)β		:∂(A'B)/∂B = A, ∂(B'AB)/∂B = 2AB

	 FOC : ∂SSR/∂β 
	 = -2s_xy + 2S_xxβ^ = 0
	 X'X β^ = X'y				/ 역행렬이 존재 = Multicollinearity이 없다고 가정
	β^ = (X'X)^(-1)X'y
      k x 1   k x k    k x 1

	simple regression : β는 설명변수가 종속변수에 미치는 영향
★	mutiple regression: β는 marginal effect, 다른 조건이 동일할 때, 설명변수의 한계효과

  해석 : X₁= 5.43, 1제곱 피트만큼 넓어지면 주택가격은 5.43달러만큼 더 비싸다. 
	 simple regression에서 coefficient, X₂= 13269.98	/ 침실이 하나 더 많을 때마다 주택가격이 13269.98 더 비싸다.
★	 mutiple regression에서 coefficient, X₂= 2824.61	/ 면적, 욕실수, 층수가 동일할 때, 침실이 하나 더 늘어나면 2824.61더 비싸다.
	
	위 차이는 mutiple regresion이 다른 조건이 동일할 때, 성립하기 때문
	coefficient = 계수, corelation = 상관관계
	
★	simple regression의 계수값 : 
	침실의 개수가 많다는 것은 필지 면적이 클 경향이 있음, 욕실이 많을 가능성도 있음, 층수도 많을 가능성도 있음
	이는. 침실의 개수가 순수하게 주택가격에 영향을 주는 것인지, 다른 요인들에 의해 주택가격이 높다는 것임
	= 과대추정 되어있다.

★	Omitted variables bias : 변수 생략함으로 나타나는 과대추정 = simple regression의 문제
	R²(종속변수의 변동성을 얼만큼 모형으로 설명하고 있는가)가 낮으면 Omitted variables bias를 생각해봐야 함 = 설명변수를 추가
	즉, R²값을 통해 Omitted variables bias를 식별할 수 있음
	
	따라서, 종속변수에 대한 모든 요인들을 찾고 이를 설명변수로 놓고 추정해야 함
	하지만 완벽한다는 것은 현실에서 불가능
	
	mutiple regression의 문제
★	설명변수가 너무 많으면 계수의 추정값에 대한 정확도가 떨어짐 → 신뢰구간이 너무 넓어지고 p-value가 너무 높아짐(통계적 유의성↓)

★	  = Multicollinearity : 설명변수간의 상관관계가 지나치게 correlation이 높을 때 발생
			      : 설명변수가 너무 많아져서 상관성이 높은 설명변수가 생길 것이고 Multicollinearity이 발생
★				 = t-통계량이 낮거나, 신뢰구간이 넓어지고, p-value가 높아짐
★				 = 설명변수가 많을수록 R²(적합도)는 높아지긴 함, 단, 계수값에 대한 통계적 유의성이 떨어짐
				 = 이런경우, 몇몇 변수들을 제외시켜야 한다. = 중복된 정보

	학군, 상업시설의 상관성이 높을 것 


  역행렬이 존재 = Multicollinearity이 없다
	X	설명변수가 K개 만큼 존재	= X'X는 full rank square matrix = invertable
     (T x K)					  (KxK)

 	ex) 만약, 설명변수를 3가지 구성했는데, x(2t) = x(3t)가 완전히 일치한다.
		yt = β₁x(1t) + β₂x(2t) + β₃x(3t) + ε(t)
		   = β₁x(1t) + (β₂+ β₃) x(2t) + εt	/ 소비t = β₂GDPt + β₁Inft + β₃GDPt라면 
								/ 똑같은 변수를 넣고 추정하고자 한다면 따로 추정하는 것은 말이 안됨
								/ 이렇게 되면 값이 무한대값이 나옴
		
	굉장히 상관관계가 높은 변수를 넣게되면 β값이 이상한 값이 나오고 신뢰구간이 넓어짐, p-value가 높아짐

	ex) 시뮬레이션, T = 50개, Y = 0.5X₁+ 2X₂+ ε	/ X₁=0.5, X₂= 2
	    상관계수가 X₁과 X₂가 0.98이 나옴

		Yt = α + β₁X₁_t + β₂X₂_t + ε	/ {X₁_t, X₂_t, Yt} → β₁, β₂
							/ X₁과 X₂의 상관성이 굉장히 높은 것으로 구성
		
		추정 결과는 : coefficient : X₁= 2.08, 	p-value : X₁= 0.03 
					    X₂= 0.147		  X₂= 0.87	신뢰구간 안에 0이 들어감

		계수값이 다르고 p-value가 굉장히 높다. 0과 거리가 가깝다 = 설명력이 높다고 할 수X

	이걸, simple regression으로 구해보면 
		추정치 : β^₁ = 2.23,  실제값 : β₁= 0.5
		p-value는 낮게 나와서 설명력이 좋다고 할 수는 있지만 true값과는 굉장히 먼 값이 나옴

		추정치(β^₁)은 사실상 β₂의 것도 포함되어 있음. X₁이 X₂와 상관성이 굉장히 높기때문
		X₂의 계수값 = 2 → 추정치에 영향
-----------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------
교재예시 a,d / 미국예시 b,c

GDPCA : 연 
CPIAUCSL :  소비자 물가지수 월별
UNRATE : 실업률 월별

save rawdata;  		/ rawdata로 저장
load rawdata; 		/ rawdata를 이미 저장했기에 다시 저장할 필요 없음

월별 자료를 연 자료로 변환

[ gdp_a(2:end,1) 100*diff(log(gdp_a(:,2)))];	/ 증가율은 첫번째 날짜는 반영되지 않으므로 2번째 날짜부터
						/ 1950~2020

cpi_m           = cpi_m_raw.Data;		/ 데이터만 따로 뽑아온 것
uem_m           = uem_m_raw.Data;

[ cpi_m(1:12:end,1) mean(reshape(cpi_m(:,2),12,size(cpi_m,1)/12),1)'];
cpi_m(1:12:end,1)								1:end = 첫번째부터 마지막까지
 첫번째 달만 뽑아서 추출							1:12:end = 첫번째 열, 첫번째 행으로 시작하는데 그다음은 13번째 행
										따라서 연간 인덱스와 같아짐

mean(reshape(cpi_m(:,2),12,size(cpi_m,1)/12), 1)'				/ reshape 만들어라

(cpi_m(:,2),	 	12,		size(cpi_m,1)/12)	size(cpi_m,1) = 864의 값(행의 개수)	
모든행의 2번째열 	행이 12개     	열(12달로 나눔) 72개의 열

열벡터를 행과 열로 표현 → 행은 월, 열은 연도

mean(reshape(cpi_m(:,2),12,size(cpi_m,1)/12), 1)'
위의 방식으로 나타낸 1월~12월까지의 평균을 내라	= 1행, 72열이 되고 거기에 '를 붙여 72행, 1열로 변환

inf_a           = [ cpi_a(2:end,1) 100*diff(log(cpi_a(:,2)))];

2008 금융위기, 코로나

OLS = fitlm(xx,yy);	/ xx 설명변수, yy 종속변수

필립스 곡선 : 60년대, 2000년대 뚜렷함, 실업률 ↑, 인플레이션 ↓ 상충관계, 상관

2010년대 오쿤의 법칙은 관계성이 떨어진다.


-----------------------------------------------------------------------------------------------------------------------------------------
-중간고사----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------

80년대 초반이 지나면 변동폭 자체가 줄어듦 = 대안정화기

CPI는 소비자물가지수이므로 증가율로 바꿔야 인플레이션율이 됨
실업률은 월별 자료임

실업률(x축)-인플레이션율(y축) : 실업률이 ↑ 경기 안좋음(GDP)
			      : 실업률이 ↓ 경기 좋음(GDP)

미국의 실업률 : 안좋은 시기마다 실업률이 ↑(70년대 초중반 = 오일쇼크, 80년대 초반, 90년대 초중반, 2000년대 중후반 = 금융위기)
근데, 인플레이션은 대게 경기가 좋을 때 높아지고, 경기가 나쁠때 낮아짐

실업률과 GDP가 역의 관계가 있다는 것은 눈에 보인다 = 오쿤의 법칙
★★★★★★
필립스 곡선 : 인플레이션율과 실업률간의 관계를 보여줌

	: 경기가 나쁠 때 = 인플레이션이 낮아지거나 디플레이션 = 실업률 ↑
	: 경기가 좋을 때 = 인플레이션이 높아짐 = 실업률 ↓
	= 역의 관계에 있다.

  	: 산점도를 그렸을 때, 실업률이 높았을 때 인플레이션이 낮아지는 경향이 보인다.
	: 산점도를 그렸을 때, 인플레이션율과 실업률간의 역의 관계가 나타나더라

	역의 관계를 발견하고, 통화정책 시행할 때, 인플레이션 압력이 높아지면 금리를 높이고 인플레이션 압력이 낮아지면 금리를 내리는 경기안정화 정책을 시행
	인플레이션을 낮추기 위해서 금리를 올렸을 때, 실업률이 높아지는 방향으로 갈 수 있다.
	즉, 인플레이션과 실업률은 상충관계에 있다!
	통화정책을 통해서 두마리 토끼를 달성할 수는 없다. 정책적인 목표가 상충될 수 있고 이 상충되는 목표를 적절하게 조합해서 통화정책을 수행해야 한다.

그러나 70년대가 되면 이러한 (인플레이션율과 실업률)역의 관계가 깨지기 시작함 = 스테그 플레이션
기존에 필립스 곡선 하에서 상충된 목표를 가지고 통화정책을 수행했을 때, 사회후생을 더 낮추는 결과를 불러올 수 있다.

우리나라 실업률-인플레이션 관계
	90년대는 역의 관계가 성립하는 것을 볼 수 있음, 나머지는 뚜렷하지 않음
-----------------------------------------------------------------------------------------------------------------------------------------
미국
                   Inflation vs. Unemployment Rate    GDP growth vs. Unemployment Rate
                   _______________________________    ________________________________

    1950년대                  -0.26876                             -0.4031            
    1960년대                  -0.84374                            -0.19639            
    1970년대                   0.14698                           -0.088665            
    1980년대                  0.082591                            -0.33085            
    1990년대                   0.43374                            -0.57237            
    2000년대                  -0.86326                            -0.79849            
    2010년대                   0.21989                            -0.23496            
    표본기간 전체              0.15176                            -0.39498            


인플레이션 - 실업률 : 필립스 곡선
	그림 : 50-60년대는 역의 관계가 보이고
	       70년대는 스테그플레이션으로 역의 관계가 보이지 않음

	표   : 50, 60, 2000년대는 음의 상관관계가 보이지만 표본기간 전체로는 음의 상관관계가 나오지 않음


GDP성장률 - 실업률 : 오쿤의 법칙
	그림 : 좀 더 안정적, GDP성장률이 높으면 실업률이 낮고, 경기가 좋으면 실업률이 낮다
	     : 음의 상관관계가 뚜렷함.
	표   : 음의 상관관계가 뚜렷함.

한국

                Inflation vs. Unemployment Rate    GDP growth vs. Unemployment Rate
                _______________________________    ________________________________

    2000년대               -0.22051                            0.25744             
    2010년대               -0.12978                            0.11674             

	표 : 필립스 곡선은 음의 관계가 미약하게 보이고, 오쿤의 법칙은 음의 관계가 보이지 않음 = 대안 지표인 고용보조지표(확장실업률 지표)로 확인하기도 함
-----------------------------------------------------------------------------------------------------------------------------------------
잔차항을 제곱해서 다 더하면 SSR, SSR이 최소화 되도록 하는 빨간선 = OLS선형회귀선

LinearModel에 원하는 자료들이 모여있음, 

 1. coefficient(설명변수 β헷)
	2번 행 : Estimate : 추정값, 설명변수 β
	       	 SE(standard error) : 계수값에 대한 표준오차
		 tStat : t-통계량
		 pValue

 2. Residuals(잔차항) : Raw = 5개의 관측치에 대한 잔차항(빨간 선 상에서의 fited value와 파란 점에서의 차이를 보여줌) 즉, 계산된 잔차
		      : 이 값들을 제곱해서 더하면 SSR이 됨

 3. Rsquared - ordinary : 0과 1사이의 값을 가짐, Y의 전체 변동 폭 대비 선형회귀선에 의해 설명되는 fited value의 변동 폭(상대적인 비중)
			: 이 회귀선이 자료에 대해서 얼마나 Y의 변동폭을 잘 설명하느냐를 보면 30% 정도의 설명력을 갖고있다.
		ex) 0.31이라면 30%정도의 설명력을 갖고있다.


BETA11_CI   = coefCI(FIG51_hat,[0.01 0.05 0.1]);    % 99%, 95%, 90% 신뢰구간

     99%(좌)		       95%(좌)		      90%(좌)		     99%(우)		     95%(우)		     90%(우)
-12.2049769095667	-7.07851026565858	-5.47974222809439	10.3217437529532	5.19527710904513	3.59650907148094
-3.64139937703700	-1.56940653573748	-0.923223470708085	5.46335194445272	3.39135910315320	2.74517603812381


	1. 신뢰구간 안에는 항상 β^, 추정치가 가운데 포함이 되어야 하고
	2. 신뢰구간의 %가 높아 질수록(신뢰수준을 높일수록) 신뢰구간의 길이가 길어짐
---------------------------------------------------------------------------
추정된 계수:
                   Estimate      SE       tStat     pValue
                   ________    ______    _______    ______

    (Intercept)    -0.94162    1.9284    -0.4883    0.6588		관측값 개수가 너무 작다.
    x1              0.91098    0.7794     1.1688    0.3269		pValue가 너무 크다 = 설명력이 굉장히 떨어짐, 통계적 유의성이 떨어짐

결정계수(R²): 0.313

상수 모델에 대한 F-통계량: 1.37, p-값 = 0.327
   -7.0785    5.1953			(알파)
   -1.5694    3.3914	 [신뢰구간]	(베타)
---------------------------------------------------------------------------
중요! 설명력이 높은지 낮은지, 통계적인 유의성이 떨어지는지 이런 얘기들을 해야함, 사진은 jpeg, 제출은 PDF

---------------------------------------------------------------------------
추정된 계수:
                   Estimate      SE        tStat       pValue  
                   ________    _______    _______    __________

    (Intercept)    -0.13208    0.55614    -0.2375       0.81276		관측치는 많아졌다.
    x1               1.0393    0.17198     6.0434    2.7318e-08		pValue가 낮다 = 기울기의 통계적인 유의성이 굉장히 높아졌다.
								 	따라서, 계수값이 상당히 높은 설명력을 갖고있는 것으로 추정된다.

결정계수: 0.271		R²가 높아진 것은 아니지만

   -1.2357    0.9716
    0.6980    1.3806		신뢰구간도 범위가 +~+에 위치하고 있다. 0으로부터 충분히 멀다고 판단할 수 있다.
				결국, pValue가 낮고 t-통계량이 높게 나오고 표준오차는 추청치에 비해서 상대적으로 낮게 추정이 된다.
---------------------------------------------------------------------------
---------------------------------------------------------------------------
추정된 계수:
                    Estimate        SE         tStat        pValue   
                   __________    _________    ________    ___________

    (Intercept)    -0.0080132      0.02781    -0.28814        0.77385
    x1                 1.0026    0.0085589      117.14    3.9168e-107	pValue가 굉장히 낮다 = 이 좋다. 기울기의 통계적인 유의성이 굉장히 높다
									t-통계량 굉장히 높고 표준오차가 추정치(Estimate)에 비해서 굉장히 낮은 수준이다.
									0일 확률이 pValue와 같다.
관측값 개수: 100, 오차 자유도: 98
RMS 오차: 0.097
결정계수: 0.993, 수정된 결정계수: 0.993
상수 모델에 대한 F-통계량: 1.37e+04, p-값 = 3.92e-107
   -0.0632    0.0472
    0.9856    1.0196				0으로 부터 멀다. 
						결론, 추정 회귀선은 굉장히 이 좋은, R²도 높아 Y의 변동성을 잘 설명하고 선형회귀선이 잘 설명하고 있다.
---------------------------------------------------------------------------

빨간 선이 선형회귀선(절편과 기울기값을 이용한 선)
3번 케이스 : SSR이 작고, 기울기가 설명력이 좋다.
---------------------------------------------------------------------------
HousePrice~LotSize

선형 회귀 모델:
    HousePrice ~ 1 + LotSize

추정된 계수:
                   Estimate      SE       tStat       pValue  
                   ________    _______    ______    __________

    (Intercept)      34136      2491.1    13.703    6.2754e-37
    LotSize         6.5988     0.44585    14.801    6.7699e-42


관측값 개수: 546, 오차 자유도: 544
RMS 오차: 2.26e+04
결정계수: 0.287, 수정된 결정계수: 0.286
상수 모델에 대한 F-통계량: 219, p-값 = 6.77e-42
   1.0e+04 * 	

    2.9243    3.9029		10^4승을 각각에 곱해라
    0.0006    0.0007
---------------------------------------------------------------------------
평수가 넓어지면 넓어질수록 집값이 비싸지더라 이러한 경향은 상관계수를 통해서, 회귀선을 통해서 양의 기울기를 갖고있으므로 확인가능하다.
-----------------------------------------------------------------------------------------------------------------------------------------
연간 경제성장률, 인플율, 실업률 : 날짜를 x축, 성장률을 y축
				: 금융위기, 코로나 등의 위기가 존재

	실업률, 인플레이션율 : 60, 2000년대 비교적 필립스 곡선의 우하향하는 모습이 보임, 상충관계가 존재함

	필립스곡선 : 통화정책의 목표 : 물가안정과 완전고용을 위해서 인플레이션과 실업률을 둘다 안정화시키는 것
		   : 이런 상충관계가 있을 때는 실업률을 낮추려하면 인플레이션율이 높아지고 인플레이션율을 낮추려고하면 실업률이 높아지는 딜레마에 있다.
		   : 60년대, 2000년대 뚜렷했다.
		   : 하지만 나머지 연도에서는 그렇지 않을 수 있다.
		   : 상충하지 않는다면, 둘다 원하는 목표 방향으로 가면 될 것이다.
		   : 그러나, 양의 관계는 통계적 유의성이 매우 떨어지므로 의미가 없다. 
			결정계수도 낮고, pValue가 높게 나온다.
		   : 시계열 자료를 놓고 봤을때는 필립스 곡선의 상충관계가 통계적으로 뚜렷하다고 보기에는 어렵다.

	빨간선(회귀선)과 파란점에 붙어있으면 통게적으로 유의성이 있다. 기울기의 가파름과는 상관없다.

	상관계수랑 pValue는 단일회귀 모형(설명변수 1개)에서 pValue로 해석한결과와 상관계수로 해석한 결과가 같을 것
	단 다변량회귀분석에서는 달라질 수 있다.


	오쿤의 법칙 : 상관계수만 보더라도 통계적으로 관계성이 보임
		    : 그림상으로는 90년대, 2000년대 2010년대에 -관계가 보임

		    : 금융위기 이후에 실업률 지표가 경기와의 상관성이 약화되었다고 보고있음
		    : 2010년대가 되니 관계성이 떨어지더라

우리나라 필립스 커브, 오쿤의 법칙
	필립스 커브 : 통계적 유의성(pValue)이 떨어짐, R₂도 그렇고..

	오쿤의 법칙은 양의 관계가 나옴, 통계적 유의성이 높은 +는 아니지만 설명력이 좋진 않다.

-----------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------
Dummy variable
	외환위기, 금융위기 등의 관측된 데이터는 평상시 데이터와는 너무나도 다른 양상을 보여줌
	통상적인 관계가 드러난 결과가 아니기때문에 그 시점에 특정 Dummy variable을 넣는다.

  주택가격의 예시
	Dummy variable : 있냐 없냐로 0,1로 표시가 가능함
	drive way, recreation room, basement, gas central heating, air conditioning

	Yt = α + βD(t) + ε(t)		/ D는 0아니면 1

★	OLS 추정 : Y^t = α^ + β^ D(t) 

★	더미변수는 0아니면 1이기에 주택가격 평균은 에어컨이 없으면 Y^t = α^, 있으면 Y^t = α^ + β^

			coefficient
★	intercept	59884.85	/ 에어컨이 없는집 평균 : 59884.85
★	D		25995.74	/ 에어컨이 있는집 평균 : 85881(에어컨이 있는 집이 없는 집보다 평균적으로 25995.74만큼 더 비싸다.)

  Multiple regression with Dummy
	
	Yt = α + β₁D₁(t) + ... + β_k D_kt +ε(t)

			coefficient
★	intercept	47099		/ 둘 다 없는 집의 평균 47099
	D₁		21159		/ 에어컨이 있으면 21159만큼 비싸짐
	D₂		16023		/ drive way가 있으면 16023만큼 비싸짐

★	┌ D₁=0, D₂=0 : Y^ = α : 둘다 없는 집의 평균
	├ D₁=0, D₂=1 : Y^ = α^ + β^₂: drive way가 있는 집의 평균
	├ D₁=1, D₂=0 : Y^ = α^ + β^₁: 에어컨이 있는 집의 평균
	└ D₁=1, D₂=1 : Y^ = α^ + β^₁+ β^₂: 둘다 있는 집의 평균

	더미 변수를 여러개 해놓는 것은 집이 갖고있는 특성을 분류한 것
	상수항에 더해지는 것이므로 계수값에 대한 해석은 간단 : 평균적인 가격에서 추가적으로 얼만큼 비싸지는가
	
  더미변수와 설명변수를 함께 사용하기

	Yt = α + β₁D(t) + β₂X(t) + ε(t)		/ 설명변수는 필지면적, 더미변수는 에어컨

★	에어컨이 없는 집 : Y^t = α^ + β^₂X(t)		/ 기울기는 같으나(β₂) 절편값이 다름(α)
★	에어컨이 있는 집 : Y^t = α^ + β^₁+ β^₂X(t)		/ 기울기는 같으나(β₂) 절편값이 다름(α + β₁)

	평행한 선 두개를 그리지만 절편값이 다른 회귀선을 동시에 그림
	OLS : 최소화되는 α, β₁, β₂를 찾는 것

  다중회귀 - 더미 & 설명변수

	Yt = α + β₁D(1t)+ β₂D(2t)+ β₃X(1t) + β₄X(2t) + ε(t)

	마찬가지로 4가지 경우가 나옴. 단, 기울기는 다 같다

★  기울기를 바꿔보고 싶다면, interaction term

	Yt = α + β₁D(t)+ β₂X(t)+ β₃D(t)X(t) + ε(t)		/ D(t)X(t) : interaction term

	에어컨이 있는 주택가격 : Y^ = (α^+β^₁) + (β₂+ β₃)X(t)	/ 기울기 : (β₂+ β₃)
	에어컨이 없는 주택가격 : Y^ = α^+ β₂X(t)			/ 기울기 : β₂

	interaction term이 (+)라는 것 : 에어컨이 없는 집들은 절편도 낮고 기울기도 낮다. 에어컨이 있는 집들은 절편도 높고 기울기도 높다

  시계열자료 : 같은 변수를 시차를 두고
	     : non-stationary : 구간별로 나눠서보면 평균과 분산이 다르다. ex) GDP의 추세적 상승이 구간별로 다르기 때문에 non-stationary이다.
	     : 단, 소비의 경우를 생각해보자. c(t) = α + βy(t) + ε(t)		/ y(t) : 소득수준
	     : 소득이 1원 올랐을 때, 소비가 얼마나 오르냐(maginal), 이를 non-stationary 과정으로 추정하면 β값이 이상하게 나옴
	     : 장기성장 추세에 의해서 올라간 것인지 아니면 maginal하게 소득이 1원 올랐을 때, 소비가 올라간 것인지 구분이 불가
	     : 이런 경우를 spurious regression이라고 함
	
		어느 구간에서든 평균, 분산이 비슷한(stationary) 자료의 시계열자료를 다룬다.
		성장률로 하여 표현하면 대략 평균, 분산이 비슷하게 만든다.
		 : γ^(GDP)_t = GDP(t) - GDP(t-1) / GDP(t-1) 

		우리나라는 짧은 기간내에 성장이 급격하게 변했기 때문에 장기적인 경향성을 나타내기 어려움
		60,70, 80, 90, 2000이후 따로 설명을 해야함. 표본자료의 누적, 꾸준한 관계를 나타내는 경향성을 찾기 힘듦
		우리나라 GDP 성장률만 계산해도 non-stationary하게 나옴

	Distributed Lag Models
	종속변수에 대해서 설명변수가 시계열 자료에서 어떤 영향을 미치는가
		통화정책, 재정정책 : 정책금리를 중앙은행이 한분기에 두번씩 발표함, 
		정책금리를 낮추면 경기를 부양하는, 인플레이션 압력을 줘서 총수요 압력을 줘서 경기를 부양시킨다(인플레이션 유발)
		금융시장은 상대적으로 즉각적으로 반응하지만 실물경제는 시차를 두고 영향을 받는다.
		재정정책 : 금융위기 이후 전세계적으로 낮은 금리를 유지하고 있다가 경기가 회복되는거 같아서 금리를 약간 올리다
			   코로나 판데믹에 금리를 다시 낮췄음. 저금리를 장기간 유지하다 보니까 일반적인 물가수준에 비해
			   자산가격에 거품이 생기기 시작함. 

		
	    Yt = α + β_0 Xt + β₁Xt-1 + β(q) X(t-q) + εt		/ Yt : 자산가격, Xt : 이자율
									/ 누적적인 영향이 Yt에 미치고 있다.

		t-1, .. t-q까지의 q시점까지의 과거의 변수들이 들어간 것 : lagged variables
		q 자체는 : lag order, lag length

		lagged variable들이 각각의 다른 설명변수인 것으로 취급해서 OLS추정을 한다.
		Y 종속변수, X설명변수, Xt-1, Xt-2, Xt-3, ... Xt-q : 시점을 달리해서 다른 설명변수인 것처럼 취급

		Table 9.1) 사고의 위험을 줄이는 정도, 설명변수 : 트레이닝 시간

		Yt = α + β_0 Xt + β₁Xt-1 + βq Xt-q + εt
		q가 가장 과거로 간 시차인데 어떻게 결정할지? 
		단일회귀에서 다중회귀로 늘릴때의 장점 : omitted variable vias를 최소화, 지나치게 늘리면 Multicollinearity의 문제가 발생
		시차를 늘리면 늘릴수록 모형의 적합도는 높아지지만  Multicollinearity의 문제가 있을 수 있고, 계수값에 대한 통계적 유의성이 떨어질 것
		너무 적게하면 omitted variable vias가 있을 수 있음
	최적화된 수준의 설명변수의 개수(lag order = q)가 필요하다.
		1. brute force method : Yt = α + β_0 Xt, Yt = α + β_0 Xt + β₁Xt-1, ...
			각각을 비교해서 β계수에 대한 통계적 유의한지 안한지 판단(β₁, β₂...를 판단)
		= Sequential t-test method

		2. AIC and BIC methods : Information criterion
		A.I.C → 각각의 목적함수를 만들어서 이를 최소화 시키는 q(lag length)를 찾는 것
		B.I.C → 
-----------------------------------------------------------------------------------------------------------------------------------------
2016~2020 : 공식실업률 지표는 실업률이 안잡히고 고용보조지표에서는 실업률로 잡힘
	  : 고용보조지표가 노동시장의 현실적인 여건을 잘 반영하고 있다.

기말고사 : omitted variable bias → R-squre를 보면 알 수 있음
-----------------------------------------------------------------------------------------------------------------------------------------
Univariate time series model

	: 시계열 자료들은 대게 non-stationary이다. (정상성이 없다, 구간을 나눴을 때, 평균 혹은, 분산이 구간별로 다르다)
	: 미국의 개인소득 시계열 자료(y축 : log) : 자연로그 수준의 개인소득을 시간에 따른 추이로 나타낸 그래프
		ex) great moderation 역시, 1980년대 전후, 구간별로 평균은 비슷하나 분산에 큰 차이를 보임

	→ 증가율 형태(ex. 로그차분 : log(yt)-log(yt-1))로 바꿔야 stationary한 process가 된다.

	시계열 자료의 상관계수 : 자기상관계수(두 변수간의 상관계수)
		1차 자기상관계수 r₁= corr(Yt, Yt-1)		/ 2, ... T
		2차 자기상관계수 r₂= corr(Yt, Yt-2)		/ 3, ... T
		p차 자기상관계수 rp = corr(Yt, Yt-p)	
			
	자기상관계수의 증가율 형태는 전년도를 없애기 때문에 기간을 줄일 수 밖에 없음
	자기상관계수의 마지막 시차까지 계산할 수 있는 것은 표본자료의 개수보다 적을 수 밖에 없다.
	: p < T
		       2020.Q4
	cov(xt,xt-1) = 1/(T-1)∑(x(t)-x(-)) x (xt-1 - x(-))
		       1953.Q2

	-1 < p < 1
	자기상관계수 : 1에 가까움 소득수준이 증가하는데 이번기의 소득수준은 저번기의 소득수준에서 약간 변하는 것이기 떄문
	증가율 기준의 자기상관계수: 낮음 - stationary
	
	자기상관계수를 그려놓은 것 : correlogram
		x축 : 시차O, 시점X
		y축 : 상관계수 혹은 log수준
		증가율의 자기상관계수 : 시차가 5인 부분에서 -라는 것은 5분기 이전의 증가율과 반대방향으로 갈 수 있는 경향
	
		: 로그수준의 소득은 시차를 두고 자기상관계수가 높다 = 과거를 기억한다, long-memory behavior = non-stationary
		: 증가율은 그러한 특성이 나타나지 않는다. stationary
	
	AR모형(autoregressive)
		: 선형회귀 모형, 설명변수가 종속변수의 시차변수들을 갖고 식별한 것
		: Y(t) = α + ∮Y(t-1) + ε(t)		t = 2,...,T
		 종속변수	설명변수

		∮= 0, α=0.01 → 그래프가 0.01에서 왔다갔다한다. ∮= 0 : 변동성이 굉장히 크다.
		∮= 0.8, α=0.01 → 그래프의 지속성이 보인다. 
		∮= 1 → 추세적으로 올라감

		|∮| < 1 : stationary
		|∮| = 1 : non-stationary, Unit root(단위근)
		|∮| > 1 : 고려대상X

	단위근
		: 단위근이 존재한다 → non-stationary
		: AR(1)모형의 ∮ = 1
		: 시차의 길이가 늘어나도 자기상관계수가 1에 가깝다, 
		: 평균이 구간에 따라 확연히 달라지는 추세적시계열
		: 단위근이 존재하면, 로그차분을 하면 stationary가 됨, 추세가 제거됐을때
		  어떤 계수가 AR모형으로 추정을 해봤는데 계수값이 1이었으나 차분을 했더니 1이 아닌경우 difference stationary
	
		: Y(t) = α + ∮Y(t-1) + ε(t) 에서 양변에 -Y(t-1)를 하면
		: Y(t)-Y(t-1) = α + ∮Y(t-1)-Y(t-1) + ε(t)
		AR(1)의 [ΔY(t) = α + ρY(t-1) + ε(t)]		/ ρ≡∮-1
	
		ex) ∮ = 1 → ρ = 0	종속변수는 차분변수, 설명변수는 수준변수
					단위근이 존재한다고 하면 ρ=0이어야 함.

		OLS추정에서 나온 ρ(^)이 0인지 아닌지를 검정하면 됨		/ t-test : β가 0이냐 아니냐를 판단

	예시) random walk : 단위근이 존재하는 확실한 예시
		AR(1), Y(t) = α + Y(t-1) + ε(t) : t시점에서의 y는 이전시점의 y와 같다. 다만, 상수항과 랜덤한 요소에 의해 움직인다.
		α = drift라고 함
		자산가격, 주식가격이 이에 해당

		일반적으로는 시차를 여러개로 확장할 수 있음
		Y(t) = α + ∮₁Y(t-1) ... ∮(p)Y(t-p) + ε(t)

		ΔY(t) = α + ρY(t-1) + r₁ΔY(t-1)...r(p-1)ΔY(t-p+1) + ε(t)	: ρ값이 0이냐 아니냐로 단위근의 여부 판단(0이면 단위근 존재)

	예시) Deterministic time trend model : 뚜렷하게 선형추세가 있는 것
		Y(t) = α + δt + ε(t)		/ 선형추세선이 존재, t= 1,..,T
		
	혼합된 모형
		AR(1)에 Deterministic time trend를 추가			/ ↔ stochastic trend : 추세가 랜덤하게 변동
		Y(t) = α + ∮Y(t-1) + δt + ε(t)	
			: ∮ = 1, δ= 0이면 단위근이 존재
			: ∮ = 0, δ≠0이면 Deterministic time trend만 존재

		δ≠0 → 선형추세(일정한 선)

	AR(p) 모형에 Deterministic trend를 추가
		일반화된 모형 : ΔY(t) = α + ρY(t-1) + r₁ΔY(t-1)...r(p-1)ΔY(t-p+1) + δt + ε(t)

		자기상관계수에 의해 Y 자체의 상관관계가 높을 것이므로 multicollinearity가 발생할 가능성
		그러나, 수준변수(ρY(t-1))가 하나만 있고, 나머지는 차분변수에 해당하므로 차분변수들과의 상관관계가 높지 않기때문에 문제X

	계절성 : 
		seasonally adjusted, 계절조정된 자료들을 이용해야 함 ↔ 원계열(계절조정X)
		원계열의 경우, 더미변수를 통해 계절조정이 가능
			ex) D₁= 1이면 1분기, D₂= 1이면 2분기, D₃= 1이면 3분기, 모두 0이면 4분기
		
      ΔY(t) = α + ρY(t-1) + r₁ΔY(t-1)...r(p-1)ΔY(t-p+1) + δt + ε(t)
	
	: 시차(p)가 몇까지 인지 확인하는 방법 : Sequential t-test method(brute force method)
					    : AIC, BIC

	: Deterministic trend(δ)가 0이냐 아니냐 : t-test		
		: 귀무가설 : δ= 0, δ(^)이 0에서 가까운지 먼지 확인
		: p-value가 작다면 굉장히 멀어진 것 → δ ≠ 0 → Deterministic time trend가 존재

	: 단위근(ρ)의 판단 : Dickey-Fuller test를 해야함. Critical value가 다르기 때문
				Critical value보다 작으면 멀지 않은것
				1. AR(p) model with deterministic trend를 test
				2. t-통계량을 가지고 특정한 Critical value에 대해 비교, 귀무가설 : ρ = 0(단위근이 존재한다.)
					ρ = ∮-1 → ∮<1, ρ<0 : ρ가 충분히 (-)인가, 아니면 0에 더 가까운가
					ρ(^)이 Critical value(-3.45)보다 -쪽으로 더 멀어졌으면 0으로 부터 충분히 멀고, 단위근이 존재X
					ρ(^)이 0에 가까우면 단위근이 존재
				3. deterministic time trend가 없으면 Critical value = -2.89
-----------------------------------------------------------------------------------------------------------------------------------------
실습 : 6장확인 - [β값의 의미, t-통계량을 통해 β의 유의성]

  Multiple regression model
	ex) 주택가격 : 면적, 방의 개수, 화장실 개수, 층수 등이 주택가격에 영향
	XY-plot에서 회귀선을 확인

	t-통계량을 통해 β가 유의성을 갖는지 확인

	SSR = ∑(Y - α^ - β^₁X₁- β^₂X₂- ... - β(k)^X_k)²= ∑ε(t)²

	회귀분석 모형을 하면서 
	β = 해당 설명변수가 한단위가 늘어났을 때, 종속변수가 얼만큼 변하냐 = 민감도, 기울기
	   = log를 씌우면 탄력도가 됨

	mutiple regression: β는 marginal effect, 다른 조건이 동일할 때, 설명변수의 한계효과

	β₁이 X₁에 영향을 미치는 

	omitted variable bias : 설명변수를 찾아내는 것

	simple → multiple에서 가장먼저 확인해야 할 것.[R²]
	simple : R²= 0.287 = 28%
	multiple : R²= 0.536 = 53%
	→ omitted variable bias는 simple과 multiple의 Lot Size를 비교하면 확인 가능
	simple의 Lot Size는 순수하게 평수가 넓어서 나온 값이라기 보다는 여러 요인들(화장실, 층수 등)이 섞여있는 효과가 주택가격을 높이는 것
	multiple이 simple보다 틀릴 가능성이 적다.

	pValue : 0.01, 0.05, 0.10이어야 통계적 유의성이 있다고 말함
-----------------------------------------------------------------------------------------------------------------------------------------
autoregressive distributed lag model(ADL model)

  ADL model : Yt = α+δt+φ1Yt−1+...+φpYt−p+β0Xt +β1Xt−1+...+βqXt−q+et

  1. X와 Y가 staionary한지 확인 → 단위근이 존재하지 않으면 ADL모델 사용가능
  2. 둘다 staionary하거나 둘 다 단위근이 존재(non-staionary)

  2-1. staionary하다고 판단되면 ADL모델 적용 OLS방식으로 추정치. t-겁정, p-value 등..

	계수값들을 가지고 모형의 누적적 효과를 분석하기 위해서는 ADL모델을 사용하기 어렵다.
	staionary한 process라 하더라도 Xt, Yt의 시차변수들이 값이 level값으로 들어가면 자기상관 계수가 높은 시계열일 가능성이 높다.
	  → Multicollinearity의 문제가 발생

	통상적으로는 ADL 모형을 구상한다고 하면 아래의 형식으로 사용	/ ∆ : 차이, δ: 선형추세의 계수값

      ∆Yt = α + δt + ρYt−1(레벨변수) + γ1∆Yt−1 + ... + γp−1∆Yt−p+1 +θXt + ω1∆Xt + ... + ωq∆Xt−q+1 + et

	: 설명변수가 ∆(차분)으로 들어가면 자기상관계수가 급격하게 줄어듦, 레벨변수를 제외하고 나머지는 차분변수기 때문에 상관계수는 낮은상태
	→ Multicollinearity의 문제가 줄어듦

	: 누적적인 효과, 설명변수 내에서 변화가 하나 일어났을 때, 종속변수가 변하게 되는 누적적인 효과
	  = [Long run, total multiplier : 승수효과] → 모형을 t시점에서 설명변수 하나 변한게 Y가 얼만큼 변했는지, 수렴할 때까지 변화한 총량

	: 재정승수 : 정부지출 1원 ↑ GDP는 얼만큼 늘어나는가
		Yt = Ct + It + Gt + NXt		→ 정부가 정책변수 Gt를 바꾸는데	/ C 민간소비, I 민간투자
	총소득 = 총생산 = 총지출

		Ct, It : 민간경제 주체들이 정부가 지출을 늘렸을 때, 그것과 상관없이 의사결정을 하느냐
		신고전학파 = 아니다. 민간소비와 투자가 정부의 행태에 대해 반응함 = C와 I가 바뀐다.
		정부가 지출을 늘린다는 것은 세금의 부과로 올테니 세금부담으로 인한 부의 감소로 저축을 해야되니 소비↓
		결국, 소비와 투자가 줄어듦 → 총생산(수요)에서 G를 늘렸지만 C, I가 떨어지므로 Y의 변동이 없음

		신고전학파적 관점이 맞는지 케인즈학파적(정부지출↑ 부양효과, C, I↑) 관점이 맞는지 판단 : G를 늘렸을때, Y의 변화 = 재정승수효과

		대게, 정책변수의 변화는 시차를 두고 영향을 줌 Yt만 볼게 아니라, Yr+1, Yt+2 .. 도 살펴보아야 함
		
	특정 경제변수가 다른 경제변수에 영향을 미치는 영향을 판단하기 위해서는 차분형태의 ADL 모형으로 누적승수효과를 계산

 	∆Yt = α + δt + ρYt−1(레벨변수) + γ1∆Yt−1 + ... + γp−1∆Yt−p+1 +θXt + ω1∆Xt + ... + ωq∆Xt−q+1 + et

	Xt : t시점에서 X의 변화가 Yt : Y수준에 미치는 누적적인 효과, 특정수준에 수렴하고 난 뒤의 누적적인 변화량
	long-run multiplier : -θ/ρ

	  : ΔY(t) = α + ρY(t-1) + ε(t)에서
	  : 만약에 ρ=0이면 φ = 1 : 단위근이 존재한다 = ρ=0이다. = non-staionary = long-run multiplier : -θ/ρ = ∞
	  : 단위근이 존재하지 않으려면 φ < 1, ρ < 0 → staionary : long-run multiplier : -θ/ρ 해석가능
	따라서, X와 Y가 staionary한지 확인해야 함

	long-run multiplier : -θ/ρ : 

	ex) pvalue는 낮게 잘 나왔고
	ex) 1.041, 컴퓨터 구입을 1%늘리면 기업의 매출이 1.041% 궁극적으로 늘어나더라

  2-2. 둘 다 단위근이 존재(non-staionary)

	Yt = α + βXt + et	OLS는 β(^)을 줌, 대게 통계적 유의성이 굉장히 높다.
				R²도 굉장히 높게 나올 것

	단위근이 존재할 때는 단순회귀 모형의 분석결과가 잘못된 방향으로 갈 수 있다. = spurious regression problem.
	이유 : 추세자체가 있는 것들끼리는, 추세적으로 변한 부분이 다른 외생적 요인에 의한 것일 수 있기 때문

    그런데 Cointegration관계라면 해결할 수 있다.
	
	Yt = α + βXt + et 
	εt = Yt  -α - βXt : linear combination, X와 Y가 non-staionary하다면 εt 도 non-staionary
	그런데, εt 가 staionary로 판명이 되면 X와 Y는 Cointegration관계를 갖고있다 한다.
	X와 Y는 추세를 공유하고 있었고 계산 과정에서 서로 제거가 된다면 추세가 제거되기에 staionary로 판명될 수 있다.

	Cointegration(공적분) : integration이 적분 = 추세가 있다. 
		common trends, co-trending : 시계열 상 다른 경제변수가 같은 추세를 갖고 올라감
		단위근이 존재하는 non-staionary의 수준변수를 OLS로 해버리면 spurious regression result가 나타난다.
		error term이 staionary한 결과가 나온다.

		ex) 일반 오렌지가격과, 유기농 오렌지 가격
			Cointegration관계 : 같은 추세로 올라간다.

		example : 장단기 금리 : yield curve, 추세를 공유하고 있다.
			: 구매력 : 각국의 구매력은 장기적인 수준에 있어서 같이간다.
			: 영구소득가설 : 인생을 3구간으로 나눠보면 소비자체는 소득흐름보다 평활함, 소득수준과 소비수준은 같이감
			  (= 장기적 공적분)
		
	오차항에서의 staionary한지 검정하기(= Engel-granger test)
		1. Yt = α + βXt + et 를 추정 → α^,β^  → ε^t = Yt  -α^ - β^Xt
		2. Dickey-Fuller test → 잔차항(ε^t)에 대해서 단위근 검정, 추세를 갖고있는지 아닌지
		3. 단위근에 대한 귀무가설을 기각 : ε^t = staionary, 단위근이 없다.(공적분 관계O)

	Xt, Yt
	1. Dickey-Fuller test(단위근 검정) → staionary(단위근 X) → ADL(p,q)모형
	2. Dickey-Fuller test(단위근 검정) → non-staionary(단위근) → Engel-granger test(공적분관계 확인)
		공적분 관계가 없으면, 차분형태로 바꾸면 됨. ∆Xt, ∆Yt
		공적분 관계가 있으면, Error correction model(= 오차수정모형, 단기적인 관계 식별)

	OLS, ECM은 반드시 중요

	Error correction model : 공적분관계가 있으면
		LR : Yt = α + βXt + εt			/ εt : staionary로 판명됨(ε^t)
		SR : ∆Yt = ϕ + λet−1 + ω0∆Xt + εt		/ et = ε^t

		공적분관계가 있으면, 장기식에서의 오차항이 단기식에 들어감
		λ < 0

		et−1이게 +라고 하면, Yt = α^ + β^Xt + εt : Y가 X보다 전반적인 추세선에서 높다.
		Y가 줄어들거나 X가 늘어나야 간격이 좁아짐 : 이런 오차를 수정하도록 하는 항(λ)
		λ가 -라는 것은 Y를 떨어뜨리는 것(장기식에서의 오차가 +라는 것은 단기식에서 종속변수를 감소시키도록 하는 역할)
		
		반대로, 장기식에서의 오차가 -라면 Y가 X가 공유되는 추세선보다 밑에 있다. Y가 X보다 낮다
		Y늘려야 오차가 줄어들기에 λ가 -가 되어야 +가 되면서 Y가 늘어나게 됨

		λet−1 : 오차수정항	λ< 0	바로 이전기에서의 차이를 이번기에 해주는 것

		장기식과 단기식 두개가 합성되서 나와있는 것. 장기식에서의 잔차항이 단기식에서의 구조를 식벽하는 역할
		
		단계 : 오차항은 모르는 변수이기에 2가지 방법으로 나눠서 해야함
		1. 장기식을 먼저 추정 후 잔차항 파악
		2. 잔차항을 단기식의 설명변수로 대입

		단위근이 존재하고 공적분이 없다고 한다면 차분된 데이터만 가지고 하면됨. ADL모형
		차분변수로만 이루어진 ADL모형 : ∆Yt = α+δt+φ1∆Yt−1+...+φp∆Yt−p+β0∆Xt+...+βq∆Xt−q+et
		ρYt-1과 θXt가 없는데 단위근이 존재하면 ρ가 0이 되어버림
-----------------------------------------------------------------------------------------------------------------------------------------
실습 = 기말대비★★★★★★★★★★★★★★★
-----------------------------------------------------------------------------------------------------------------------------------------
전년동기대비 경제성장률 : 대략적인 평균이 점점 낮아지는 모습, 
			: 분산 = 변동성, 최근에 들어서는 안정적인 모습 = 지속성장의 모습, 선진국형 경제모습

고성장 시기에 인플레이션 변동성은 큰 경우들이 대게 많다. 변동성이 많이 줄어들었다.

거시지표들의 시작점이 다리기 때문에 시점을 맞추어야 한다.

고용보조지표와 공식실업률은 실업률에 큰 차이가 있는데 이는 실업자의 범주를 확장해서 했기때문에 실업률은 높아질 수 밖에 없다.
2016년에 청년실업문제 = 구직활도을 하다가 단념한 사람들이 공식실업률에 안잡히고 고용보조지표에서는 잡힘(고용보조지표 실업률이 높다.)
		      = 현실적 여건을 잘 반영하고 있다.

필립스 커브 : 인플레이션-실업률 : 고용보조지표3에 비해서 공식실업률이 좀더 강한 역의 관계
				: 표본기간을 나눠보면 공식실업률이 2010년대에 좀 더 강하게 나온다.

	종속변수는 인플레이션률이고, 설명변수는 상수항과 더불어 실업률지표이다.

	표준오차 : 

★	귀무가설 : β = 0에 대해 기각하지 않을 확률(쉽게 말하면 β = 0일 확률)
		 : β = 0, 설명변수가 종속변수에 대해서 설명력이 없다.
		 : p-value가 높으면 β = 0을 기각하지 못함 = 귀무가설이 맞을 확률이 높음 = 설명력을 가지지 못할 확률이 높다.
		 : p-value가 낮으면 β = 0을 기각함 = β≠0 설명력이 높다. 계수값의 추정치는 통계적 유의성이 있다.
	
★		 : p-value : 1%, 5%, 10%에 따라 기각여부가 결정. 1%이내 = 굉장히 낮은확률, 5%이내 = 꽤 낮은 확률, 10%이내 = 그래도 낮은 확률
			→ β = 0을 기각, 설명변수의 설명력이 꽤 있다 = 통계적유의성이 꽤 있다.
			
	표에 추정치(pvalue), 결정계수를 놓고 보면 공식실업률이 통계적 유의성이 높은, 인플레이션에 대해 설명력이 높은 것으로 나옴
	기간에 따른 차이 : 2010년대에 통계적 유의성이 더 높다.
	표본기간 전체를 놓고 봤을때, 고용보조지표의 전체적 기간에 대한 통계적 유의성이 높아졌는데 이는 표본자료가 많아졌기 때문

★	결정계수(R²) : 종속변수의 변동성에 대해 설명변수가 얼만큼의 변동성을 설명하고 있는지
		      : 모형에 의해 설명되는 Y의 변동/전체적인 Y변동 = 모형 자체의 설명력을 보여줌
		      : R²= 1 : 모형과 전체적인 변동이 일치한다는 것

★	결정계수(R²)가 0.16정도라는 것은 인플레이션 변동성을 모형이 16% 정도 설명하고 있다는 것으로 
	선형회귀 종속변수의 변동성이 80%이상 설명되지 않는다. 즉, 실업률만 가지고 인플레이션률의 변동성을 다 설명하기에는 어려움이 있다.
	omitted variable bias(생략된 변수 편의) = R²를 보면 알 수 있다.

	+ 우리나라는 제조업 중심의 국가이므로 해외 원자재와 같은 수입재 가격에 민감하게 반응하고 우리나라의 인플레이션은 해외의 가격변동에 의한 영향을 많이 받는다. = 소규모 개방경제
	  따라서, 인플레이션률의 변동성을 실업률만을 가지고 설명하기에는 어려움이 있다.

	중앙은행의 통화정책에 있어서 책무로 알려진 물가안정과 고용안정 간의 상충관계는 아직까지 공식실업률 기준으로 필립스커브를 고려해야할 것으로 판단된다. 
	다만, 고용보조지표의 시계열자료가 아직 짧은 것을 감안할 때, 보다 긴 기간이 확보될 경우 이러한 선형회귀모형의 추정결과는 다시 검토되어야할 것으로 사료된다.

오쿤의 법칙 : 경제성장률-실업률
	1. 오쿤의 법칙의 경우 대체로 고용보조지표3가 경제성장률과의 관계에 있어서 더 높은 상관관계를 보이고 있다. 표
	2. 이는 고용보조지표3가 최근에 와서는 경기상황을 더 잘 반영한다는 것을 시사한다.
	3. 표본기간 중 2000년대에는 고용보조지표3의 설명력이 다소 떨어지나, 2010년대부터 최근까지는 경기 상황에 대한 설명력이 매우 높아졌음을 알 수 있다.
	4. 경기 안정화를 도모하는 우리 나라의 정책 당국은 경기 변동과 더불어 노동 시장의 여건을 보다 엄밀하게 파악하기 위해서는 확장된 범
	   주의 실업자를 포함한 고용보조지표를 면밀히 모니터링해야할 것으로 판단된다.
-----------------------------------------------------------------------------------------------------------------------------------------
★★★★★★★★★★★★★★★★★★★★★
HousePrice~LotSize Model					→ simple regression

선형 회귀 모델:
    HousePrice ~ 1 + LotSize

추정된 계수:
                   Estimate      SE       tStat       pValue  
                   ________    _______    ______    __________

    (Intercept)      34136      2491.1    13.703    6.2754e-37	→ 상수항
    LotSize         6.5988     0.44585    14.801    6.7699e-42	→ 필지면적(6.5988) : 다른 조건들이 생략되어 있음(상관계수를 보면 필지면적이 화장실개수, 침실개수 등과 양의 상관성을 갖는 것으로 보임)
										    : 순수하게 평수가 늘어나서 비싸기 보다는 침실의 개수, 화장실 개수 등으로 인한 영향이 주택가격에 포함되어 있는 것일 수 있다.
관측값 개수: 546, 오차 자유도: 544
RMS 오차: 2.26e+04
결정계수: 0.287, 수정된 결정계수: 0.286				→ R²가 multiple regression에 비해 상대적으로 낮게나옴 = omitted variable bias의 문제가 있다.
상수 모델에 대한 F-통계량: 219, p-값 = 6.77e-42	
   1.0e+04 *

    2.9243    3.9029						→ 상수항에 대한 신뢰구간(기본 신뢰수준 95%)
    0.0006    0.0007						→ 필지면적 계수값에 대한 신뢰구간(기본 신뢰수준 95%)

--------------------------------------------------------------
HousePrice~HousePrice~LotSize+Bedrooms+Bathrooms+Stories Model	→ multiple regression

선형 회귀 모델:
    HousePrice ~ 1 + LotSize + Bedrooms + Bathrooms + Stories

추정된 계수:
                   Estimate      SE        tStat       pValue  
                   ________    _______    _______    __________

    (Intercept)    -4009.5      3603.1    -1.1128       0.26629
    LotSize         5.4292     0.36925     14.703    2.0463e-41	→ LotSize는 simple gression과 multiple regression에서 둘다 설명변수로 사용됨
    Bedrooms        2824.6      1214.8     2.3252      0.020433	   = simple gression과 multiple regression에서의 LotSize 차이가 bais가 되는 것
    Bathrooms        17105      1734.4     9.8621    3.2894e-21	   다른 조건이 영향을 끼치지 않고 동일하다고 했을때, 평수만 늘어난다고 하면 주택가격이 5.43만큼 늘어난다 = 한계효과가 5.43
    Stories         7634.9        1008     7.5745    1.5703e-13	   simple regression보다 틀릴 확률이 적다.

관측값 개수: 546, 오차 자유도: 541
RMS 오차: 1.83e+04
결정계수: 0.536, 수정된 결정계수: 0.532				→ multiple regression에서는 R²가 개선됨(설명변수를 추가해 전반적인 을 높임)
상수 모델에 대한 F-통계량: 156, p-값 = 1.18e-88
   1.0e+04 *

   -1.1087    0.3068
    0.0005    0.0006
    0.0438    0.5211
    1.3698    2.0512
    0.5655    0.9615
--------------------------------------------------------------
ForestLoss~CropCH Model							→ CropCH만 따로 봤을 때,

선형 회귀 모델:
    ForestLoss ~ 1 + CropCH

추정된 계수:
                    Estimate        SE        tStat        pValue  
                   __________    ________    ________    __________

    (Intercept)        1.1792     0.14584      8.0857    1.5316e-11	→ 통계적으로 봤을때 가까운지 먼지의 측정은 표준오차를 갖고 측정 = t-통계량
    CropCH         -0.0058603    0.013535    -0.43299       0.66639	→ pValue가 66%로 높다. CropCH의 통계적 유의성이 워낙 떨어짐
									= t-통계량을 보고 0에서 먼지 가까운지를 판단할 때, pValue가 0에 가깝냐 아니면 높은 숫자인가
									= pValue가 낮으면 낮을수록 t-통계량은 0에서 멀리 떨어져있는 것, t-통계량과 pValue는 매칭됨
관측값 개수: 70, 오차 자유도: 68
RMS 오차: 0.934
결정계수: 0.00275, 수정된 결정계수: -0.0119				→ CropCH를 넣어서 R²를 높이는 기여도에 의미가 거의 없다.
상수 모델에 대한 F-통계량: 0.187, p-값 = 0.666				   pValue에서 변수자체가 설명력이 굉장히 떨어진다. 통계적 유의성이 낮아서 개선의 효과가 없다.
    0.8882    1.4702
   -0.0329    0.0211
--------------------------------------------------------------
ForestLoss~PopulationDensity+CropCH+PastureCh

선형 회귀 모델:
    ForestLoss ~ 1 + PopulationDensity + CropCH + PastureCh

추정된 계수:
                          Estimate         SE         tStat        pValue  
                         __________    __________    ________    __________

    (Intercept)             0.56567       0.13271      4.2625    6.5715e-05
    PopulationDensity    0.00080774    0.00011356      7.1131    1.0192e-09	→ t-통계량도 굉장히 크고, pValue가 작은 것 = 추정치는 0에서 멀리 떨어져있다 = 설명변수인 인구밀도는 종속변수에 대해 굉장히 높은 설명력을 갖고있다.
    CropCH               -0.0039748      0.010214    -0.38915       0.69842	→ 변수가 무의미, pValue가 70%인 것 = 추정치는 0에서 가까운 숫자라는 의미
    PastureCh              0.027966      0.010003      2.7957     0.0067749


관측값 개수: 70, 오차 자유도: 66
RMS 오차: 0.674
결정계수: 0.495, 수정된 결정계수: 0.472
상수 모델에 대한 F-통계량: 21.6, p-값 = 7.45e-10
    0.3007    0.8306
    0.0006    0.0010
   -0.0244    0.0164
    0.0080    0.0479
-------------------------------------------------------------- 만약 변수간의 상관성이 너무 높다면 Multicollinearity의 문제가 발생(추가적인 정보량이 없음)
-----------------------------------------------------------------------------------------------------------------------------------------
ELETRICITY 유형★★★★★★★★★★

선형 회귀 모델:
    Cost ~ 1 + Output + LaborPrice + CapitalPrice + FuelPrice

추정된 계수:
                    Estimate         SE        tStat       pValue  
                    _________    __________    ______    __________

    (Intercept)       -70.495        12.695    -5.553    1.7593e-07	
    Output          0.0047311    0.00010945    43.226    3.4054e-74
    LaborPrice      0.0036268     0.0010553    3.4366    0.00081415	→ 1%이내 유의수준에서 귀무가설이 기각, 따라서 통계적 유의성이 높다.
    CapitalPrice      0.28008       0.12949     2.163      0.032557	→ 상대적으로 봤을때, 통계적 유의수준이 떨어지는게 capital price이며 설명변수가 너무 많을때
    FuelPrice         0.78346       0.16579    4.7257    6.3918e-06	   Multicollinearity의 문제를 최소화 하기위해 이런것부터 먼저 제거함
									   그렇게 했을때, R²가 크게 나빠지지 않고 여전히 설명력이 있는 모형이라고 하면 설명변수를 제거한게 Multicollinearity를 피할 수 있는 좋은 선택이 될 것
관측값 개수: 123, 오차 자유도: 118
RMS 오차: 13.6
결정계수: 0.944, 수정된 결정계수: 0.942						→ 설명변수가 많아지면 많아질수록 개선되는 통계량 R²
상수 모델에 대한 F-통계량: 495, p-값 = 9.73e-73
  -95.6347  -45.3555
    0.0045    0.0049
    0.0015    0.0057
    0.0237    0.5365
    0.4552    1.1118
-------------------------------------------------------------- 
선형 회귀 모델:
    Cost ~ 1 + Output + LaborPrice + FuelPrice

추정된 계수:
                   Estimate         SE        tStat       pValue  
                   _________    __________    ______    __________

    (Intercept)      -49.758        8.4493    -5.889    3.6831e-08
    Output         0.0047357    0.00011111    42.622    6.3988e-74	→ capital price를 제거했음에도 통계적 유의성이 높다.
    LaborPrice     0.0033129     0.0010613    3.1215     0.0022591
    FuelPrice        0.85159       0.16527    5.1528    1.0314e-06

관측값 개수: 123, 오차 자유도: 119
RMS 오차: 13.8
결정계수: 0.942, 수정된 결정계수: 0.94					→ capital price를 제거했기에 결정계수가 조금은 떨어지지만 큰 영향을 주지 않음
상수 모델에 대한 F-통계량: 639, p-값 = 3.5e-73
  -66.4885  -33.0276
    0.0045    0.0050
    0.0012    0.0054
    0.5243    1.1788
-------------------------------------------------------------- 
★★★★★★★★★★
선형 회귀 모델:
    HousePrice ~ 1 + AC							→ 더미변수 하나 추가

추정된 계수:
                   Estimate      SE      tStat       pValue   
                   ________    ______    ______    ___________

    (Intercept)     59885      1233.5    48.549    7.0777e-200		→ AC없는 집값 평균 = 59885
    AC              25996      2191.4    11.863     4.9727e-29		→ AC있는 집값 평균 = 59885 + 25996

관측값 개수: 546, 오차 자유도: 544
RMS 오차: 2.38e+04
결정계수: 0.206, 수정된 결정계수: 0.204		
상수 모델에 대한 F-통계량: 141, p-값 = 4.97e-29
   1.0e+04 *

    5.7462    6.2308
    2.1691    3.0300
-------------------------------------------------------------- 
선형 회귀 모델:
    HousePrice ~ 1 + Driveway + Recreation				→ 더미변수 두개 추가

추정된 계수:
                   Estimate      SE      tStat       pValue  
                   ________    ______    ______    __________

    (Intercept)     47099      2837.6    16.598    2.4168e-50
    Driveway        21160      3062.4    6.9095    1.3671e-11		→ 있으면 이걸 더하고, 통계적 유의성은 높다
    Recreation      16024      2788.6    5.7461    1.5234e-08		→ 있으면 이걸 더하고, 통계적 유의성은 높다

관측값 개수: 546, 오차 자유도: 543
RMS 오차: 2.48e+04
결정계수: 0.141, 수정된 결정계수: 0.137					→ 결정계수는 낮은데 이는 Dummy variable로만 구성해서 집값을 설명하기에는 모자르다. = 즉, omitted variable bias가 분명히 존재하고
상수 모델에 대한 F-통계량: 44.4, p-값 = 1.38e-18			   = 주택가격에 있어서 가장 핵심적인 주택면적이 생략되어있기 때문에 결정계수가 낮게 나올 수밖에 없다.
   1.0e+04 *

    4.1525    5.2673
    1.5144    2.7176
    1.0546    2.1502
-------------------------------------------------------------- 
    HousePrice ~ 1 + LotSize + AC					→ 더미변수와 설명변수를 함께했을 때(y절편만 다르고 기울기는 같음)

추정된 계수:
                   Estimate      SE       tStat       pValue  
                   ________    _______    ______    __________

    (Intercept)      32693      2282.5    14.323    1.0543e-39
    LotSize         5.6378     0.41817    13.482    6.1184e-36
    AC               20175        1947    10.362    4.4344e-23

관측값 개수: 546, 오차 자유도: 543
RMS 오차: 2.06e+04
결정계수: 0.405, 수정된 결정계수: 0.403					→ 주택면적을 넣어보면 결정계수 20%에 비하면 설명이 잘 되고있다.
상수 모델에 대한 F-통계량: 185, p-값 = 6.7e-62
   1.0e+04 *

    2.8209    3.7177
    0.0005    0.0006
    1.6350    2.3999
-------------------------------------------------------------- 
    HousePrice ~ 1 + LotSize*AC						→ interaction term(LotSize:AC)을 추가하여 절편뿐만 아니라 기울기까지 다름

추정된 계수:
                   Estimate      SE       tStat       pValue  
                   ________    _______    ______    __________

    (Intercept)      35684      2587.2    13.792     2.626e-37
    LotSize         5.0177     0.48896    10.262    1.0664e-22		→ AC가 없으면 기울기가 5.02이다. 통계적 유의성이 있다.
    AC              7613.4      5544.3    1.3732       0.17026		→ 더미변수는 상수항의 차이만을 얘기하는 것이기 때문에 pValue는 신경쓰지 않아도 된다. 그리고 통계적인 유의성이 떨어지긴 하지만, 기울기쪽에 통계적 유의성이 낮지 않은걸보면 교차항을 넣는게 설명력이 그래도 꽤 있다.
    LotSize:AC      2.2545     0.93231    2.4182      0.015927		→ AC가 있으면 기울기가 7.27정도 이다.(기울기가 더 높아짐), 통계적 유의성이 있다.
									   = 즉, 에어컨이 있는 집이면 주택면적이 넓어지면 넓어질수록 더 주택가격이 비싸다
관측값 개수: 546, 오차 자유도: 542
RMS 오차: 2.05e+04
결정계수: 0.411, 수정된 결정계수: 0.408					→ 교차항을 넣으면 결정계수도 조금 개선이 된다.
상수 모델에 대한 F-통계량: 126, p-값 = 5.67e-62
   1.0e+04 *

    3.0602    4.0766
    0.0004    0.0006
   -0.3278    1.8504
    0.0000    0.0004
-------------------------------------------------------------- 
★★★★★★★★★★
선형 회귀 모델:
    Inflation Rate ~ 1 + 1984_Dummy

추정된 계수:
                   Estimate      SE       tStat       pValue  
                   ________    _______    ______    __________

    (Intercept)     13.222     0.47299    27.954    1.6619e-74	→ 84년 이전에 인플레이션 평균이 13%였는데
    1984_Dummy     -9.8292      0.5748     -17.1     2.502e-42	→ 84년 이후의 인플레이션 평균은 13.22+(-9.83)%이다. 약 3.4%이다.

관측값 개수: 223, 오차 자유도: 221
RMS 오차: 4.01
결정계수: 0.57, 수정된 결정계수: 0.568
상수 모델에 대한 F-통계량: 292, p-값 = 2.5e-42
-----------------------------------
공식실업률과 지표 평균 비교
    3.5587
   11.3821
-----------------------------------
2003-2021 공식실업률기준 : 필립스커브, 더미상수 : Fig 4번의 첫번째 그래프

선형 회귀 모델:
    Inflation ~ 1 + U1 + Dummy_2010				→ 종속변수가 인플레이션, 상수항, 설명변수, 더미상수

추정된 계수:
                   Estimate      SE        tStat       pValue  
                   ________    _______    _______    __________

    (Intercept)     7.3389      1.2464      5.888    1.1455e-07		→ 전반기 y절편값(상수항)
    U1             -1.2105     0.35105    -3.4483    0.00094607		→ 기울기
    Dummy_2010     -1.4939     0.20995    -7.1158    6.7572e-10		→ 후반기 y절편값(상수항+더미절편값 = 7.3389-1.4939)

관측값 개수: 75, 오차 자유도: 72
RMS 오차: 0.894
결정계수: 0.488, 수정된 결정계수: 0.474
상수 모델에 대한 F-통계량: 34.3, p-값 = 3.46e-11
-----------------------------------
2003-2021 공식실업률기준 : 필립스커브, 더미 교차항

선형 회귀 모델:
    Inflation ~ 1 + U1*Dummy_2010

추정된 계수:
                     Estimate      SE        tStat       pValue  
                     ________    _______    ________    _________

    (Intercept)        6.9368     2.3084       3.005    0.0036682	→ 원래 상수항(전반기 절편값)
    U1                -1.0964    0.65389     -1.6767     0.098006	→ 공식실업률 계수값, 2000년대 기울기(-1.0964)
    Dummy_2010        -0.9228     2.7598    -0.33437      0.73909	→ 더미상수 계수값(후반기 절편값)
    U1:Dummy_2010    -0.16131    0.77718    -0.20756      0.83617	→ 교차항에 대한 계수값, 2010년대 기울기(-1.0964-0.16131)

관측값 개수: 75, 오차 자유도: 71					→ 통계적 유의성은 비교하기 어려운 측면이 있다.
RMS 오차: 0.9								   표본자료를 반으로 자른 것은 표본자료의 개수가 달라서 통계적 유의성을 직접적으로 비교가 어렵다
결정계수: 0.488, 수정된 결정계수: 0.467					   오히려 떨어지는 측면도 있다. 그러나 추정치로만 놓고보면 기울기, 표본기간 내에서 기울기의 변화를 알고싶다면 더미변수를 활용하면 좋다
상수 모델에 대한 F-통계량: 22.6, p-값 = 2.28e-10
-----------------------------------
2003-2021 고용보조지표기준 : 오쿤의 법칙, 더미 교차항
 
이 부분에서 기울기가 많이 변했는데 오쿤의 법칙의 경우 고용보조지표 기준으로 후반기에 설명력이 높아졌음, 전반기에는 그닥이었음 
즉, GDP, 경기변동에 대해서 설명력이 높아졌음. 그것이 결과에 있어서 유의성이 드러난 것
-----------------------------------
필립스 커브는 공식 실업률이 설명력이 있다고 나왔었고
오쿤의 법칙은 고용보조지표가 설명력이 있다. 더미변수를 넣으면 통계적 유의성이 떨어지는 경향이 있었다. 
-----------------------------------
10년간 별로 더미변수를 만든다면 60년대를 한다면 60년대만 1로 하고 나머지는 0으로 하면됨, 이런식으로 더미변수를 블락으로 만들어서 확인가능

50년대 : 0  
60년대 : 1
70년대 : 0
80년대 : 0
-----------------------------------------------------------------------------------------------------------------------------------------
생산 단기 예측 : 단기, 중기, 장기는 명확하지 않지만 단기는 = 월별, 금융 = 일별, 주별, 시간

통계청의 생산지수는 월별 단위로 제공 - 생산활동과 관련된 것 중 광공업 생산모형이 많이 사용됨
GDP의 추계는 분기별로 제공, 통계청에서는 생산(개념적으로는 GDP와 같음)을 월별로 조사해서 집계화 시킴

광공업생산모형 : 제조업에 해당되는 광공업 생산을 한달예측하는 모형
	       : 매달 초에 두달전 생산지표가 나옴(10월달게 나왔을 것이고 이를 통해 11월달을 예측해보자)

월별 생산예측 모형 = 한달 미리 예측하는 것으로 변수는 다음과 같음

    광공업(제조업) 생산모형 : 조업일수, 평균전력생산(핵심적 생산요소는 전력), 수출, 제조업 BSI 실적치, 주가지수 등
	1. 조업일수 : 달력 상에서 일하는 날(working day)

	2. 평균전력생산 : 전력은 제조업에서 핵심적인 생산요소, 여름과 같이 에어컨으로 전력이 많이 사용되는 경우 = 계절조정 필요
			: 한달 전 것을 알 수 있다. 다만, 공개적으로 공유되는 자료가 아니기에 여기서는 제외

	3. 수출 : GDP의 다른 지출계정보다 빠르게 집계됨, 제조업을 통한 상품수출이 많기에 연관이 되어있음
		: 단, 선박, 석유제외 = 규모가 커서 숫자가 잘못잡힐 수 있음
		: 선박을 수주해서 만들고 인도하는 시점에서 카운트 되는 수출액 = 통계를 왜곡

	4. 주가지수 = 금융지표를 활용해서 예측가능할 것

	5. 제조업 BSI 실적치 = 기업체를 대상으로 설문조사를 하여 제조업관련 기업의 실사지수(마치 소비자심리 지표처럼)

    서비스업생산모형 : 신용카드 국내승인액, 아파트 매매거래량 및 주식거래대금
    건설업생산모형 : 시멘트국내출하량 및 건설수주


광공업생산예측 : 광공업생산지수(IIP)

	광공업 생산 : ΔY(t) = ρΔY(t-1) + βΔX(t) + ε(t)	/ Δ : 차분, ΔY(t) = Y(t) - Y(t-1), 증가율 = ΔY(t) = log IIP(t) - log IIP(t-1)
		     (11월 달)   (10월 달)	(11월 달)

	지금 사용할 IIP는 계절조정이 안되어있음 = 계절조정이 안된 지수를 갖고 활용할 때, 전년 동월대비로 계산을 함
	ΔY(t) = Y(t) - Y(t-12)		/ 12달 전 증가율

	풀어서 쓰면 : 
	∆광공업생산t = β0 + β₁∆조업일수t + β₂∆평균전력생산량t+β₃∆KOSPIt + β₄BSI 실적치t + β5∆총수출액t+ β6∆광공업생산t−1
				 (증감)		(자료가 없으니 사용X)		    (BSI level)

		Δ조업일수는 증감이다.
		BSI는 level값을 그대로 사용, 애초에 추세가 제거된 상대적인 지표이기 때문에 차분할 필요X

	실제 : Yt = βXt + ε
	fitted value(모형 예측) = β^Xt		실제와 모형의 차이가 : ε^(t)

	ECM(error correction model) : 에러코렉션 모델이 상당히 실제치와 비슷한 모양을 갖는다.


광공업 생산지수 : 금융위기 2008년도에 엄청나게 떨어짐, 2010년에 크게 반등하고 코로나때 떨어짐
총수출액 + 나머지들 다 비슷함
BSI : 기업인들이 느끼는 정도가 더 심하게 나타남, 극과 극의 느낌(심리지표 특성)

--------------------------------------------------------- → multiple regression★★★★★★★★★★
선형 회귀 모델:
    IIP ~ 1 + IIP_bac							→ 설명변수가 한 개일 때

추정된 계수:
                   Estimate       SE       tStat       pValue  
                   ________    ________    ______    __________

    (Intercept)     1.5138      0.43291    3.4968    0.00057053
    IIP_bac         0.6066     0.053904    11.253    1.8435e-23

관측값 개수: 220, 오차 자유도: 218
RMS 오차: 5.64
결정계수: 0.367, 수정된 결정계수: 0.365					→ 설명력이 낮기때문에 omitted variable bias를 의심할 수 있다.
상수 모델에 대한 F-통계량: 127, p-값 = 1.84e-23
---------------------------------------------------------
선형 회귀 모델:
    IIP ~ 1 + IIP_bac + EXP + CAL + KOSPI

추정된 계수:
                   Estimate       SE       tStat       pValue  
                   ________    ________    ______    __________

    (Intercept)     0.82791      0.2667    3.1043     0.0021641
    IIP_bac         0.34025    0.045874     7.417     2.733e-12
    EXP             0.18171    0.022993    7.9025    1.4038e-13		→ 변수를 추가해도 통계적 유의성이 높고
    CAL              1.7103     0.16681    10.253    2.4421e-20
    KOSPI          0.077345    0.014766    5.2381    3.8594e-07

관측값 개수: 220, 오차 자유도: 215
RMS 오차: 3.44
결정계수: 0.768, 수정된 결정계수: 0.763					→ 변수를 늘릴 때마다 결정계수도 올라간다.
상수 모델에 대한 F-통계량: 178, p-값 = 6.11e-67
---------------------------------------------------------
---------------------------------------------------------
선형 회귀 모델:
    IIP ~ 1 + IIP_bac + EXP + CAL + KOSPI + BSI

추정된 계수:
                   Estimate       SE        tStat       pValue  
                   ________    ________    _______    __________

    (Intercept)     -4.5994       2.789    -1.6491       0.10059
    IIP_bac         0.31147    0.047894     6.5033     5.462e-10
    EXP             0.16531    0.024335     6.7929      1.07e-10
    CAL              1.7171     0.16576     10.359    1.2127e-20
    KOSPI          0.064519     0.01607     4.0148    8.2301e-05
    BSI            0.073166    0.037429     1.9548      0.051908	→ BSI를 넣으니 다른 변수들에 비해 통계적 유의성이 상대적으로 낮은 것으로 나왔다.
									→ 물론 이정도만 해도 통계적인 유의성이 꽤 높은 것이지만 상대적으로 봤을 때, pvalue가 다른 설명변수들의 pValue에 비해 높게 나왔다.
관측값 개수: 220, 오차 자유도: 214					→ 이는 단순히 Multicollinearity의 문제가 심각하다기 보다는 설명변수가 많아지다 보니 Multicollinearity의 문제가 발생할 가능성이 있어보이는 것으로 나온다.
RMS 오차: 3.42
결정계수: 0.772, 수정된 결정계수: 0.766					→ 결정계수가 약간 높아지는 했는데		
상수 모델에 대한 F-통계량: 145, p-값 = 1.32e-66
---------------------------------------------------------
★★★★★★★★★★★★★★
---------------------------------------------------------	→ 더미변수 상수항 추가
Phillips' Curve(표본기간 전체)Dummy 상수항

선형 회귀 모델:
    Inflation_Rate ~ [예측 변수 7개에 8개 항이 있는 선형식]

추정된 계수:
                         Estimate       SE        tStat        pValue  
                         ________    ________    ________    __________

    (Intercept)            3.0374      0.5004        6.07    4.2138e-09
    Dummy_1950           -0.31501     0.44623    -0.70594       0.48082
    Dummy_1970             4.7446      0.4608      10.296    2.9762e-21
    Dummy_1980             3.4447     0.48966      7.0349    1.5739e-11
    Dummy_1990            0.81207     0.45282      1.7934       0.07401
    Dummy_2000            0.35176        0.45      0.7817       0.43506		→ 통계적 유의성이 좋지는 않았고 50년대를 기준으로 했을 때, 너무 안좋아서
    Dummy_2010           -0.34196     0.45479     -0.7519       0.45275		   그나마 60년대가 적합치와의 오류가 가장 적었음, 통게적 유의성이 가장 높은 구간이여서 60년대를 기준으로 나머지를 더미변수로 사용한 것
    Unemployment_Rate    -0.15483    0.081327     -1.9037      0.057985		→ 기울기(-0.15483) = 음의 관계가 나오긴 함

관측값 개수: 284, 오차 자유도: 276
RMS 오차: 1.99
결정계수: 0.457, 수정된 결정계수: 0.443
상수 모델에 대한 F-통계량: 33.2, p-값 = 2.44e-33
---------------------------------------------------------
---------------------------------------------------------	→ 더미변수 교차항
Phillips' Curve(표본기간 전체)Dummy 교차항

선형 회귀 모델:
    Inflation_Rate ~ [예측 변수 7개에 14개 항이 있는 선형식]

추정된 계수:
                                    Estimate      SE        tStat        pValue  
                                    ________    _______    ________    __________

    (Intercept)                      7.4708      1.3934      5.3616    1.7721e-07
    Dummy_1950                      -2.9784      1.7874     -1.6663      0.096804
    Dummy_1970                      -2.5292      2.1683     -1.1665       0.24445
    Dummy_1980                      -2.9892      2.0667     -1.4463       0.14924
    Dummy_1990                      -6.9312      2.1989     -3.1522     0.0018033
    Dummy_2000                      -1.1518      1.8422    -0.62523       0.53235
    Dummy_2010                      -5.8408      1.6383     -3.5653    0.00042973
    Unemployment_Rate               -1.0825     0.28461     -3.8033    0.00017657	→ 60년대(기준)
    Dummy_1950:Unemployment_Rate    0.53533      0.3716      1.4406       0.15085	→ 이것들과 더해야 함 = 기울기
    Dummy_1970:Unemployment_Rate     1.3845     0.38734      3.5744    0.00041577
    Dummy_1980:Unemployment_Rate     1.2027     0.35118      3.4248    0.00071082
    Dummy_1990:Unemployment_Rate      1.502     0.40668      3.6934    0.00026779
    Dummy_2000:Unemployment_Rate    0.39896     0.35401       1.127       0.26075
    Dummy_2010:Unemployment_Rate     1.0943     0.31167      3.5112    0.00052266


관측값 개수: 284, 오차 자유도: 270
RMS 오차: 1.91
결정계수: 0.512, 수정된 결정계수: 0.488
상수 모델에 대한 F-통계량: 21.8, p-값 = 5.27e-35
---------------------------------------------------------
















